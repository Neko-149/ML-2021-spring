{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5cFq_TgWlQ_"
   },
   "source": [
    "# Homework 11 - Transfer Learning (Domain Adversarial Training)\n",
    "\n",
    "> Author: Arvin Liu (r09922071@ntu.edu.tw)\n",
    "\n",
    "If there are any questions, please contact ntu-ml-2021spring-ta@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNiZCGrIYKdR"
   },
   "source": [
    "# Readme\n",
    "\n",
    "In homework 11, you will need to implement Domain Adversarial Training in Transfer Learning. As shown in the bottom left part of the figure.\n",
    "\n",
    "<img src=\"https://i.imgur.com/iMVIxCH.png\" width=\"500px\">\n",
    "\n",
    "> \n",
    "\n",
    "## Scenario and Why Domain Adversarial Training\n",
    "Now we have labeled source data and unlabeled target data, where source data might be relavent to the target data. We now want to train a model with source data only and test it on target data.\n",
    "\n",
    "What problem might occur if we do so? After we have learned Anomaly Detection, we now know that if we test the model with an abnormal data that have never appeared in source data, our trained model is likely to result in poor performance since it is not familiar with the abnormal data.\n",
    "\n",
    "For example, we have a model that contains Feature Extractor and Classifier:\n",
    "<img src=\"https://i.imgur.com/IL0PxCY.png\" width=\"500px\">\n",
    "\n",
    "When the model is trained with source data, the feature extractor \n",
    "will extract meaningful features since it is familiar with the distribution of it.It could be seen in the following figure that the blue dots, which is the distribution of source data, has already been clustered into different clusters. Therefore, the Classifier can predict the label based on these clusters.\n",
    "\n",
    "However, when test on the target data, the Feature Extractor will not be able to extract meaningful features that follow the distribution of the source feature distribution, which result in the classifier learned for the source domain will not be able to apply to the target domain.\n",
    "\n",
    "\n",
    "## Domain Adversarial Training of Nerural Networks (DaNN)\n",
    "\n",
    "Based on the above problems, DaNN approaches build mappings between the source (training-time) and the target (test-time) domains, so that the classifier learned for the source domain can also be applied to the target domain, when composed with the learned mapping between domains.\n",
    "\n",
    "<img src=\"https://i.imgur.com/vrOE5a6.png\" width=\"500px\">\n",
    "\n",
    "In DaNN, the authors added a Domain Classifier, which is a deep discriminatively-trained classifeir in the training framework to distinguish the data from different domain by the features extracted by the feature extractor. As the training progresses, the approach promotes a domain classifier that discriminates between the source and the target domains and a feature extractor that can extractor features that are discriminative for the main learning task on the source domain and indiscriminate with respect to the shift between the domains. \n",
    "\n",
    "\n",
    "The feature extractor are likely to outperform the domain classifier as its input are generated by the feature extractor and that the task of domain classification and label classification are not conflict.\n",
    "\n",
    "This method leads to the emergence of features that are domain-invariant and on the same feature distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-qnUkspmap3"
   },
   "source": [
    "# Data Introduce\n",
    "\n",
    "Our task contains source data: real photos, and target data: hand-drawn graffiti.\n",
    "\n",
    "We are going to train the model with the photos and the labels, and try to predict what the labels are for hand-drawn graffiti.\n",
    "\n",
    "The data could be downloaded [here](https://drive.google.com/open?id=12-07DSquGdzN3JBHBChN4nMo3i8BqTiL). The code below is for data downloading and visualization.\n",
    "\n",
    "Note that: **The source and target data are all balanced data, you can make use of this information.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DF-i0sVlnUbq",
    "outputId": "d1f5d9b1-abcb-4afe-bb3a-eee6bf94ceb6"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "#!gdown --id '1P4fGNb9JhJj8W0DA_Qrp7mbrRHfF5U_f' --output real_or_drawing.zip\n",
    "# Unzip the files\n",
    "#!unzip real_or_drawing.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "0_uO-ZSDoR6i",
    "outputId": "18f1a1f9-5a11-4437-a94f-5b98114c7421"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def no_axis_show(img, title='', cmap=None):\n",
    "  # imshow, and set the interpolation mode to be \"nearest\"。\n",
    "  fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "  # do not show the axes in the images.\n",
    "  fig.axes.get_xaxis().set_visible(False)\n",
    "  fig.axes.get_yaxis().set_visible(False)\n",
    "  plt.title(title)\n",
    "\n",
    "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
    "plt.figure(figsize=(18, 18))\n",
    "for i in range(10):\n",
    "  plt.subplot(1, 10, i+1)\n",
    "  fig = no_axis_show(plt.imread(f'real_or_drawing/train_data/{i}/{500*i}.bmp'), title=titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "3eMs7DbVt4Ee",
    "outputId": "1a9814f9-5956-4254-c65c-f7deb4241247"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAABnCAYAAAC5HZnbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnkUlEQVR4nO3deaBV8/rH8e+hDFdoppSSKUQSiSbKmFJCylAUMpRkLJI0KHMTIpk1mm5JhjJUhlI0km6haCBSiOqm8/vn5+m99l2r9j5777XXWefz+uuj9rA6a+81OM/zfPPy8/OdiIiIiIiIiMTTLrneABERERERERHJHt34i4iIiIiIiMSYbvxFREREREREYkw3/iIiIiIiIiIxpht/ERERERERkRjTjb+IiIiIiIhIjBVL5cF5eXla+y8L8vPz89J5vvZLdmi/RJP2SzRpv0ST9ktk/Zyfn18unRfQvskOfWeiSfslmrRfoilov+g3/iIiIiLhWp7rDRARkaIlpd/4FyZ5edv/R0eHDh0sv/zyy5Y3bNgQ6jaJiEju1K1b13LDhg0t83wRZPPmzZY/+eQTy7Nnz7b8999/p7uJIiJZVbFiRcuNGjWyPHr06FxsjoiESL/xFxEREREREYkx3fiLiIiIiIiIxFhsS/1r165t+amnnrK8atUqy5MnTw51m3Jpl122/z+eatWqWV66dGkuNkdEJCuaNWtmuU+fPp6/q1WrVsbfjy1jH3zwgeWXXnrJ8iuvvGJ527ZtGd8GEZFkXX311ZZvu+02yyr1D1/Lli0t9+jRw3Lp0qUtjxw50vLAgQND2S7xd99991n+4osvLI8ZMyYXm1Mg+o2/iIiIiIiISIzpxl9EREREREQkxmJb6t+gQQPL+fnbl4icOXNmLjYn584880zLb7zxhuWaNWtaXrhwYajbJNlTo0YNyywlq1OnjuXDDz/cMsuV161b55u///57y9OmTbO8Zs0ay8uWLbO8fv36Amy5pOqQQw6xfN5551lmew9bnLjvnHNu+fLCv6rYlVdeaXn48OGWFyxY4Hlc+/btLY8bN87ypk2bdvoe++67r2VOwm7SpIllHmf5+vPmzbN85513Wp40adJO31dEJJOOOuooy2r3DB9//myvWLx4sW8eMGCAZZ6rBg0alKUtFCpZsqTlm266yTLP6yr1FxEREREREZFI0I2/iIiIiIiISIzFttS/VKlSllkaw9LlomTOnDmWWQJ88sknW1apf+FTr149y/fcc49llh9v3brVMvfxrFmzLO+1116WOU2WLQPNmze3zEnAxPd68803PX83dOhQy1OmTPF9viTn2GOPtcyfZZkyZVJ+rRUrVlhmGwAz24NWr16d8ntkw80332z5gQcesPz6669bbtu2rec5mzdvLvD7sR1mwoQJvjkvL89yixYtLPft29cyf5Ys4WQLgHPeFjWRwqhq1aqW2XZTokQJ38fzOzZ37lzLs2fPtjxs2DDL3333XfobWQRVr17d8pdffrnTxx922GGWWaa+ZMkSy4sWLcrQ1sXfxRdfbJnH+caNG1v+9ddfLXNVmN69e1seMmSIZa0Wkz2nn3665WLFtt82H3fccZYrVqxoma2VUaTf+IuIiIiIiIjEmG78RURERERERGIstqX+xYsXt8zy46KKJXTEEm+Jvmuvvdbz34MHD7bMqftdu3a1/Oyzz1ree++9LbNcv2PHjpa3bNni+95sAbjuuuss33DDDZbLlStn+eyzz/Y8n60CDz74oOU77rjDsr6ryenWrZtl/swOPPBAy3/88YdllnOOGDHC81ps97n00kt9M1do4OR6touE4aqrrrLMz9Bzzz1nmRP+w/48sWyTLQdsB3jooYcs9+jRwzJLBZ3z/lv/+9//ZnIzc+6DDz7w/DcnInNVBsk9tg/xM8nvFo8PLFHeuHGjZZYrH3TQQZbZrsaVM/i+nTp18s0smXbOuYkTJ+7gX1K07brrrpYPPfRQy6+++qrlyy+/3DKPTSz1D8KWs/79+3v+LvH7XtTVqlXL8vz58y3zu0OTJ0+23KpVK8vly5e3zNWVJLN4zfPnn39a/te//mWZ7QC8Hoki/cZfREREREREJMZ04y8iIiIiIiISYzkp9edE6pYtW3r+7sgjj/R9DstWWQoYVGrKyYtxK5MsCE6zZomeSv2jia0qnNx6zTXXeB738ssvW2aZHkssid83lujff//9lleuXOn7XK6I0a9fP8tsJZgxY4blxYsXe57PFQVuueUWy/vtt5/l9u3b+763eHGa7PTp0y2z3YOrd3DFB05lds65Bg0a+L4Hjxmcnr3bbrulvsFp4KR8fm7ef/99y1dccYXlTE7D52ezQoUKljlxPBmcuMw2DX7X+B1MfO8LL7zQMs+FhRXbS5zzXhOwJHzt2rVhbZL8v8Rrsscff9zy/vvvn/H3++WXXyxzxYsbb7zR8h577GF5/Pjxll977TXPa916662WH3nkkUxuZqHH9ordd9/dMluj2G7Ec/nAgQMtf/bZZ5YbNWpkma2DPDY759yoUaMst2vXzvLff/+d/D+gkOD5tXv37pb5eS5ZsqTlZI5xQddkBxxwgGWV+mcWrzvYtsprIR4P2b6hUn8RERERERERyRnd+IuIiIiIiIjEWFZL/UuVKmWZE5hZlpk4dXnRokWWWQZUuXJl3+dziiunUGuqf7CgqZSSW5y4zyngLKfr3bu35zl9+vSxnEyJM6fuE8stU/XDDz9YrlOnjuXEknA+bvXq1ZZ5bJgzZ45ltjiIF1dYCCrxY3k52y5Yuuucc08++aRllscuXbrUci6Pofz8c7r0nXfeaTmT5f3E0mO2oWWqRYqffU4xd85bJvr5559bbtq0qWXuo6jj8YDnZ+e809x5jLv++uuzvl2ZUqNGDcvcL5s2bcrF5qSEP/O7777b83effvqp5VNPPdXysmXLLPNaj2XM/HNmtqt88sknlpMp/T7ttNMsJ65Q8vDDD1uuXr265c6dO1uOe+tniRIlLPP6ju1hxHM/y/45ST4I2/d4Hrnppps8j2OrAPc9V2iIOpZ+s1XpmGOO8TyOf9emTRvLbdu2tcw2PJ67Vq1aZXn58uWWec1ObAHj9SNX8fnpp598nys7dvTRR1tmCwyPH2zBSGyhjDL9xl9EREREREQkxnTjLyIiIiIiIhJjuvEXERERERERibG8VHoj8/Lydvpg9mOOGTPGMvu7BgwYYDlxyZXffvvN93X33HNPy1zSjK81bdo0y+w/O/fcc30ze57Yz8GlTnbkm2++sfzEE09YXr9+fVLP/0d+fn7ezh8VLJn9QuyvHjdunOWuXbumsxmRV7VqVcuDBg2yPHjwYMtchibs/fLCCy9Ybt26tWX2iSUuX5SqoUOHWuZMDH4/w8YlCc8880zLZcuWtcyl5cLeL1H0xRdfWObshObNm/s+/vzzz7fMn7dz3l7Yr7/+usDblK398tJLL1lmfy/nvmzZsiWdtw702GOPWWY/ZdCsjHSwh9Q57z57+umnLfO8c9JJJ1n+66+/fF83Kt8X9vEnniPZ21q+fHnLNWvWtMy+1ajgkouctcHrgcQlWGFOfn7+8em8fzr7hr3g/PlzroVzzl122WWWo7b8WuJ3hnM/OP9m6tSplvk9DrpWi8p3Zkd43Oa1G5fLY48/r/X5c+Njgo4h6erVq5dlLi3LfZF4XvIT9n4566yzLPfv399y0LwE57wzE/j54lwYzjvhUpXZmLn17rvvWuYSzs7975LLBVUYvi+puv322y3fe++9lrmsL48xvPbiMou5FLRf9Bt/ERERERERkRjTjb+IiIiIiIhIjGVkOT8u8fLmm29aZtlokyZNLBekZI8lSGwPYNk6S0Lr1atnmaX7s2fP9n19thgkW862zz77WOZSHfy3prNMWrZs3LjRcqaWpYqqCy64wPJTTz1lmUty9O3bN9RtIn5uWHp/6623Wk63vJ9Lx7Rs2dJyMsv1hGH48OGWWd7MZXHYghFHLB1nefmoUaMs87g5a9Ysy1zelKXHP/74o+Wg5YCc8y6/FRW77rqrZZbQjRw50nK2yvuJx2+WZGZDYtsdS1+5HSxb7tixo+Vhw4ZlcevSt6NzDVv2evbsaZnLHXIZw2xjKXTi9+PXX3+1HLRNiUuZRhGPFWyl5JKZzjl34oknWv7444+zv2EpSPzO9OvXz/KSJUssP/vss5anTJlimdeJbCeLCh5zEq9TunXrZpnXx2wLmjt3rmUeR1u0aOH73Gzhfjn99NMtP/roo5YnTZoU6jYF4RKDXPqWS43zuo2l9M6lfs3P67MDDzzQcrFi22/PqlWrZpnnRt5jsfXt+OO3dxBxacXPPvvM8948f7DtV7xtp1xmmp9ltllyyT8ut7xu3bpsbWKB6Tf+IiIiIiIiIjGmG38RERERERGRGMtIqX+zZs0sb9261TIn/G/YsCETb/U/uHIAS7s4iZaleZ9//rlv5lTbZNWvX9/y22+/bfnhhx+23L59+5RfN9tYxtiwYUPLLIdj+ZFz3vIiljLNmzfPMtsoWBbFz0Q2sCTKOe/kek5U/vDDDy1fcskllleuXJnFrftf/FmybGjGjBmW+RlKF0vmK1WqZHn8+PEZe4908N/N0s06depYzmWpPye0slWCJYuJU95Z1rz33ntbZnsQH8NSW2KrCgVNaGYJIleuYGtAYnksPx8zZ870fb+wHXrooZb58wu71PiPP/6wzP3F73AYk875+eeKDq1atbIc9VL/HU2sZlsKp36z7YWllzzfZgPP2yxHds47TZ2l/mwfK168eBa3ruDKlCljuUePHpb5ea5du7bnOR999JFl7g9OOS/I9VO2sXSZ14DvvPOOZbZJseUsl1im/dxzz1nm584554YMGWKZ08X5byWWH4fZNuOcc9u2bbPMz9306dN9t+mVV14JZ8P+H9tZ+H3nNRKvGTN5TcufzXfffef7mKVLl+70dbjaC691n3/+ectsh3bO20rI41e67aWFFVc64XURr8ePOOIIy7x2JT6Gx8+o0G/8RURERERERGJMN/4iIiIiIiIiMZaRUn+WvbDsMVvl/UGCyvizJag0+4477rB82223WWY5Y9hYDsySS5b+sbx2R7hf9913X9/HcCorS1PZDsDMieVsJeB7sYSNrQicYuucdzo+y0Y5FTeM8twgLN/mtNbrrrvOMsu/0tW6dWvLLF1+6623MvYe6di0aZPvnye2cGQbS7n5uenatavvNs2fP9/y8uXLPa/1/fffW+ZnmD9/rq7BvH79esuc6nzxxRdbrlChgu/jE6f2/oPfqa+++srzdw0aNLDMFVNy6ZBDDvH9c7ZzhYGrvfAYys8KHxMGlmHefffdlnksj+JqMjsq9eeqE08++aRlHhP52TzmmGMsZ6OVjG2KidvNFVdOO+00yyzTrVu3bsa3qaB4zOKqS0cffbRlnhsXLlzoeT7bmzp06OCbuWIOWwDWrFlTwK3OLJbbstWJ35lcYvk7y/ZXrFhhmatnOefctGnTUnoP7qNctnSxXYtT0XldFEapP68hR4wYYfnbb7+1zFaQbLesZsvatWstc2UH57zHg9GjR1s+++yzLRemFZXYssSyfeeC70fZpskVELga3IQJEyzz/m7//ff3fc2jjjrKskr9RURERERERCRUuvEXERERERERibGMl/qz1KIomTx5suWePXtaZjldLkv9OaGS5SmJZX3/4CRQ55y7//77LbP0+b333rPMabQnnHCCb27Xrp3lG264Ialt/8fvv/9umWWV/Bk75y3XiUrpMrF8jC0OnDacLpaxnXfeeZbfeOMNy2zHSAbLWvkZYMtA4gTsZLCEmjLZ7pDMe7Mkq0aNGpY5LZ2T8oMm8GbL4MGDM/I6iZNoW7RokZHXzaSgVQ7YEhGGoPfjSgO5LPVniTanYr/wwgtZ3w6WQrLs+8gjj7RctWpVyztqJePPmW1YbJVjWerEiRMts+WGk8953mErwU8//WT5559/tswS8MaNG/v+uXPOXX/99ZZ5nOXPvEuXLparVKliObElKAwsI+dKKeeee65l/jwrVqzoef5JJ51kmdd6LKXt3LmzZf58eEzlRPG5c+da5nGUrQFsseDni+f7xPLdsWPHWr7ooosst2nTxjI/X2G0hAa55ZZbLN97772WR44caZnn2XSPfWyVTLVNIJN4XmdJf8eOHS3z+J/qdUqyeHzgZ4qfGx434mDz5s2e/2YbD1cC4GoSBx10kOWwW2R5P8kVbHgteuyxx1quWbOm5d12283zWmyJJJ7L+X5TpkyxzBZKtl/y8Wzj5D0gr6/4HeYqCnyuc85t2bLFMo9pQasIpEq/8RcRERERERGJMd34i4iIiIiIiMRYRkr9WbKQWF5RVCxatMgySwNZ9sjSkbCx1I0l84sXL7bMkrtnnnnG83yW+rPEk9PLmVmOSiytPvjggy2zDJQrBZQsWdIyJ32zTDGx/Ijl2FHBskVOjOa2JpaUpoNtF5UqVbI8btw438cXL17cMkvdbr75ZsssqeK04eHDh6e1rVzZgJ8PTvzNluOOO84yy8RYWpr4XSjsWOrsnHdCfVTwGEMsgQtD4s/qHzwWrVy5MqzNcc4Fn2sOPPDArL93+fLlLb/77ruWWSq7evVqyyxtnzdvnuXEqd2zZs3yfT+20D3wwAOWzznnHMunnHKK5aVLl1pm+TqPb2XLlrXMic7E12E7gHPe4ynPYVyNgKX+3D6W0GYTj9UsO2UZOX8+bG1KnOLNkv4XX3zRMstf+bm4/fbbLdevX983B+Hngm0JlStXtszrl8RzJldc4GoxbBPhCkxhT9xmiTKvqdhaedVVV1nO5DVBFHG/sK2hVq1alrkKQCax/ZXefvvtrLxfFPG7dNddd1lmS+jpp59uOYyVoNg+NX36dMtsOeI5hquG8RjM47xz3mtWWrduneVXX33VMs8BxJ8Tv6s8nnKqf+nSpS3vt99+lnndlXjfXKpUKctso+J+Yds023iSod/4i4iIiIiIiMSYbvxFREREREREYizjpf4sqStKOF32l19+scyJmGHjxMkLL7zQ8uuvv255yJAhvs9lOWOidNo5WLrGUpqgspogbCtILO1nWX3YU8CDnHjiiZY5FTSTk/yJJezEcluW1nElBJYMc/py+/btLY8ePdoyv/8FwZJOmjlzZlqvm4yGDRv6/jlLvsLG7y1bXYIyS805FTtIYml/FCcXB031z9aE5yBshaKpU6daZskzV0lhqwrzqlWrLLPEneeNqOIKIcccc4xllsfeeOONljmtmMfixGnsyazgwQn/LP/lKjU8FnG1BZZ98zPE7xGnO7PUOLE96vLLL7d82GGHWT788MMtP/7445b/85//+Pxrsourq/DzxuN8sWLbL//YgpD4HeP086CVTFg23adPH8sTJkywzJLcU0891TLb0s4//3zf1ydefySeP7mv/v3vf1tmSXMutW7d2vLatWstX3nllZbjXt5PYbduUdCUd7a2JB6n4oxl/DxmcBWqMEr92cbF8v5rrrnG8hNPPJH17QjClcJ4vOEKXeniMa5Tp06WBw4caJltUWeccYZlrrwSRL/xFxEREREREYkx3fiLiIiIiIiIxFhGSv05FZFTuVmCl0wJalywVI5l3WFr0qSJZU6T5CRVlppy3+1I2FOs/VSsWNEyy0mdi2bpcpUqVXz/fMmSJVl5P64mwdJBlluytJUlXCxlTZzwnA0tWrSwzCnqYZTIsi2EP6egEj9+Ry6++GLLtWvX9jyOZb/Tpk2zzDIxljnyddnikPi6O8MJ5Dzmbt682TIn0jvnnRIfFUFT/fnvCANLm7nvWJrOkneW3FWoUMFyUAscy5FbtmyZzqaGYtKkSZbHjBlj+YILLrD81Vdfpfy6bJeoV6+e5aAVg8aPH2+ZJeuZwmPBdddd5/k7tsfNmTPH8qhRoyw3a9bMcramkifiFOu6deta5pR9tj9cf/31ltka1rRpU8/rBpX3U//+/X0fzxVi2G7Ru3dvy7xG4ioQPFe1bdvWMs/vYR8P0sUVHj744APL6bbLFVZBx8UwWgAWLFhgmd93thSxHTLuuDoWV5no1q2b5TJlyljOVmta0HeaZf/Lli2zzDZhXrcltnJkqoWG78FjGn9OPE8W5Bqfn/+hQ4da5vUdzzdsj+A1RRD9xl9EREREREQkxnTjLyIiIiIiIhJjGamRmz59uu+fN2/e3PKIESMy8VaFAktVgkpWw9CmTRvLLBHhNMgjjjjCcuXKlS2XKlXK81osReaqALnCacqJJeFRnIpbrlw53z9naXsmscyYZYTc9w8//LBlTiMPA8ujueLE3XffbTmK+5FlgJywmlhW9u2331q+9957LdeoUcPyZZddZpmT/LkSCMvEevbsaZnlZnw8WzzYarXLLtv/Hy9XxHDOO4U9KqJS6k+ciJ6MoLa3Aw44wHIU2qZSwdUJWH7N7wVXMOHqDMyJ7Sa33nqr5WuvvdYyy+qrVq1qmeX9HTp0sMwSS07nZksPP1v8HnHyO489PCY55/2+8HH8jg0fPtxy9erVLWezpJuT8rktU6ZM8X08jz8zZsywPHny5KTeb5999rFcv359yyzjZylskLPOOsty+fLlLd93332Wf/3116S2KYp4Lj700EMts3WoqApaISqM1ofZs2db7tevn+W77rrLMtvgnnzyyaxvU1Q888wzlrt37265VatWlrN1T8eVOh566CHLnTt3tswVppLFlmC2PPG4zz/ntQbvk3i9+vXXX1seMGCA73aPHTvW9zHz588P3FYeB9myzfZSnnuSWRWH9Bt/ERERERERkRjTjb+IiIiIiIhIjGWk1J9lwh9++KHle+65x/LLL79suTCXbSWDExmDppZmC0tKWRbCCbkFmR7NshJOcA6ydetWy19++aVlli6nU8rNUlG+flQFla6xZDWT5W2dOnWyzKnUa9euzdh7pIplfYMHD7bM6bCDBg0Kc5MCS6RYes9ptyzVZDl/tWrVAt+DZdAsX3366actc/UETnFleT+/w5xkG0f8+VOqJW25xOPb6tWrfXNBsF2E7QSJLRxh4nsXZDtYDs9ScU4uDvqOcTo3W6cy1UbF6ffOeUt+27VrZ5mtddxWrszx6aefZmSb/LA0laX7LCmtVKmS5Tp16ljmROpkNWrUyDLPY1OnTk3pdbgCAr8bvJYszFjqTytWrAh5S6Jnr7328v3zsFu62M7DdrnHHnvMMluEeI6OI66uQWyfCsMtt9ximS0YPHZxhS+2H5UsWdLzWvw7Zq5uxT/nSlxczYBtu7xu47U1M1f64TmC94mJ98Qs9ec5nis18Zg9ceJElwr9xl9EREREREQkxnTjLyIiIiIiIhJjGSn1pxtuuMHyzJkzLX/88ceWW7RoYZml33HBUpB169aF+t5169a1zNIk/vm4ceNC3SZiScusWbMsf/bZZ5aXLVtmmVOkmVlyHYVVBnaG5ezEcqLFixdn7P3C/tz5YYmSc86NHDnScsOGDS1fdNFFljl5NQz8mXN7WZ7Lzymn97P8K7E0ne0BnN7MyfCcqs2SMU4yv+OOOyxzinrfvn39/jmxEVQuzu9L3NsdgrD0nO1Bb7zxRi42JyNYtshJ2r169bL81Vdf+T73m2++yd6G+Zg3b57lm2++2TJXJuAUaP57smnChAm+mYLa9F577bWU34+rCHAy9pw5c1J6Ha64wNWHClNbz44EtTeyvYWrURQlXNGB+z7sYzv3yyWXXGKZ0+15XuZ5iK18zsXjcxtU0h/29Rn99ddflsNoA2KrAK+n2VpQtmxZy2yj4kpOL774omUef4NaCZzz3gNxVRaeS9JpldZv/EVERERERERiTDf+IiIiIiIiIjGW8VJ/TpDl1FeWkrEFgJPnnXNu8uTJmd6kUJQuXdoyS/05+TsMQVNSGzRoYHnVqlVZ3w5OcK9Vq5blE0880TezTJItCskoDO0ib775pmWWLLFst0uXLqFuUzYccMABljn92jnnmjZtarlr166WueJH2DiBmqWGLNU688wzLX/00UeWWeZ79NFHe1537ty5llmOzVaXoMn1LCvjdGN+p+Iu6DvN8ti4l/pzUnr//v0tX3PNNZb5OY1Ce09BsbSRk7R5THznnXcsb9iwwXJU/t0s8Q2rvD9VQSsMFGTCfOPGjS2z9DaTq9PEAcuj2cLEY1lRwvMY237Hjx9vmatChY3nXJb985zEVQAOOuggz/MvvfRSy7zWK0w46Z5yWeofNrZ18j6O9zNB7blcgYltUGwdySX9xl9EREREREQkxnTjLyIiIiIiIhJjGS/1J07DPv744y2/+uqrlidOnOh5DqdY33///VncusxiySXLlFieGAZOyCVORA6aMJ8tLIcZPXq072M4Ub1ChQqWK1eubJltIVw9gisCRBV/5sOHD7d84403Wl6wYIHlxDL5qOHE044dO1ru2bOn5V128f5/xQ4dOliOSsnTb7/9Zpn74oUXXrD81FNPWea/j3h8c85b6k/Fixe3HFQSu+eee/rmjRs3+j4+jhYuXGiZpdw8BhTmKfZ+OC3YOefGjBljuX79+pYfeughy3fddVf2Nyxkffr0scyVL9gq9Pnnn4e6TXHB1onE43MyOH2a7U08XkqwL7/80nJie1hRwdY5tsiOHTs2F5uzQ5yc3rt3b8s//vij5aFDh3qew2t+tjJEpSUpGfvvv7/vn7P8vSjh+ea4446zzHsbruTElvco0m/8RURERERERGJMN/4iIiIiIiIiMZbVUn9avXq15VNOOcXy448/7nncfffdZ7lmzZqWr7zySstRmZTZuXNny506dbJ8zz33WGZpVxiCpvr/+eefoW5HqlhSxVUHmPfYYw/LLPUvW7Zslrcus7iCQZUqVSxzmjVLqsaNGxfKdvmpUaOGZX7eOe2Wn7lJkyZZ5ooFzhVscnSYXnrpJcssdXvwwQd3+lyW8Cf7uKBSf67Awcn/Qe0DccTJyvxedO/e3TLbwr777rtQtivTTjvtNMv8/DnnnX7dqlUry6+//nrWtyuXeOzr1auXZX4Owl4tJy7SLdVNnGD+j7feeiul1+Fxjav7BE3JjospU6ZY5nmlTZs2ltniE0dt27a1vGbNGsvTpk3LxeYUCO9bfvjhB8/fjRo1yvLHH39sma1K33zzTRa3Ln1cOYaT/GfMmJGLzck5lvqfd955ltmCx3bqqN9v6Tf+IiIiIiIiIjGmG38RERERERGRGNONv4iIiIiIiEiMhdbjT+zf5BJfzjk3b948y+yBOvzwwy2zx+L777/Pxiaavffe2zL7DZ1zrlu3bpbZl8Ue/7BxWbxNmzb55sJq+fLlvn/OJf8KAy77weXJuLQll0c66qijLHMpL+e8y9GlqlKlSpbZV3711Vdb5jyO33//3fLzzz9v+dFHH7Uc9kyLbOHPed9997UctHwaZ1TsCHv899lnH8ucU8E5J8uWLbP8/vvvJ/UecTNs2DDLnDPBZWEbNWpkmZ/TqNh9990tc04BP0889znn3IUXXmg56j2h2TJixAjLrVu3tsxeaQnP7NmzLZcvX95yqksEN2vWzHK1atUsd+3aNY2ti75BgwZZ5rJ2zz33nGXOP0ic+1FYsRf6oosussxlsHldVJgkLkl+6qmnWuaSs+z3b9mypeVPP/00exu3E+XKlbPM+5v27dtb5jKGUTy3hoE9/vx+nnXWWZafeOKJULcpHfqNv4iIiIiIiEiM6cZfREREREREJMbyki1Rdc65vLy85B+cAU2aNLE8duxYy1u3brV82WWXWX733XcL/F6lSpWy3KJFC8t9+/a1XKFCBc9zuLzQbbfdZjnVsvr8/Py8nT8qGPcLl1Y7+OCDLc+fPz+dt4gElklzSUeWIjnnXL9+/TLyfpncL8ngvmP5PD/jicuEsLT+66+/9n2tMmXKWD7ssMMsJ36e/7FkyRLf7Xj22Wctp9NikK6w9wsNGDDAMpfwZKuEc84tWrTI9/k8jrF0mbZt22b5nHPOsZzqkllhC2O/sPWEP4+ZM2da5jKSCxcuTGeTUlaxYkXLXBKJ7TP77bef5eHDh1tm65hzmWvPyuX3RXZoTn5+/vHpvEBh3TddunSx3K5dO8tc2o/HwbCF8Z3hOZpL9p599tmWhw4davmRRx7xPD+ZJUyrV69umUuHMvPcxXJ0nt+4rHIy2AbinHMfffSRZV6/16pVy3Iyx7vCdiyrWrWq5cmTJ1s+5JBDLPOagvcbQcv9BilWbHvn9vHHbz+ssPWA91TOOVevXj3f5z/wwAOWuWxukMK2X1LFVsy1a9f6PqZx48aWo9KWGbRf9Bt/ERERERERkRjTjb+IiIiIiIhIjEW61P/888+3zGmvLFFmyQwnL7L0kyWhtWvXtnzGGWdYPuGEEyxzaiNLn1hC6pxzc+fO3fk/IglxL5PJhvfee88yy/6d85ZHpyMq+6VGjRqWL730Us/fceI/y/g5ffXnn3+2zJUROKGZ35cFCxZYTuX4EJao7JcCvrdlfk6rVKlimeXpH374YTgblgFh7xdORn7mmWcscxWGSZMmeZ7z9NNPW2Y53vr16y3vsccelvfcc0/f9z7iiCMsc6WBCy64wPfxr732muXBgwdb5vklWwrz9yXmimypf9SF/Z1hmTVXs2K7EB/jnLd9k20RvD5m6xHxHMNzP1cS4ZT9gQMHWmZbAtsVuFJDjx49PO+32267WWbpOd87GYX5WFaiRAnLLKVnS8WPP/5omSuXsOyfr8NVx04++WTLXDGI+3HOnDmebeJ7jBw50nKqq8gU5v2SKq4kx9V6+F1jO0suqdRfREREREREpAjSjb+IiIiIiIhIjEW61P+KK66wzBLNdGzZssUyyyzfeecd38z2gWyVPRelMplM4SoMnPbvnHM//fRTRt5D+yWatF+iKZf7haWNnKDPFjHnnKtUqVJB3yIQp/yOGDHCMld9WblyZcbfN1n6vkSWSv0jKirfGU7Hv+qqqzx/V7NmTd/nbNiwwTJbxaZOnWp59erVvs9ly9mwYcMsN23a1PIuu+z894WvvPKK57+56lWqZeQUlf2SSY0aNbLcoUMHy3Xr1rXMNg/u382bN1tm2wRbYfkZ4HMzKY77JUj37t0tc5WtIUOG5GJzdkil/iIiIiIiIiJFkG78RURERERERGIs0qX+LG9p27at5dKlS1vmBGZOxFyzZo3lH374wfK3335reePGjZnb2DQUpTKZwkT7JZq0X6IpivuFK7Q451ytWrUs16tXzzLPI8TSSE7O/uWXXyxz5YBNmzYVfGOzJIr7RZxzKvWPLH1nvNgi1bx5c8tcMYil5itWrMjKdmi/RJP2SzSp1F9ERERERESkCNKNv4iIiIiIiEiMRbrUv6hQmUw0ab9Ek/ZLNGm/RJP2S2Sp1D+i9J2JJu2XaNJ+iSaV+ouIiIiIiIgUQbrxFxEREREREYmxYjt/iMfPzrnl2diQIqxKBl5D+yXztF+iSfslmrRfokn7Jbq0b6JJ+yWatF+iSfslmgL3S0o9/iIiIiIiIiJSuKjUX0RERERERCTGdOMvIiIiIiIiEmO68RcRERERERGJMd34i4iIiIiIiMSYbvxFREREREREYkw3/iIiIiIiIiIxpht/ERERERERkRjTjb+IiIiIiIhIjOnGX0RERERERCTG/g+Q4ShxiesRqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x1296 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "for i in range(10):\n",
    "  plt.subplot(1, 10, i+1)\n",
    "  fig = no_axis_show(plt.imread(f'real_or_drawing/test_data/0/' + str(i).rjust(5, '0') + '.bmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moXQw9To5TqZ"
   },
   "source": [
    "# Special Domain Knowledge\n",
    "\n",
    "When we graffiti, we usually draw the outline only, therefore we can perform edge detection processing on the source data to make it more similar to the target data.\n",
    "\n",
    "\n",
    "## Canny Edge Detection\n",
    "The implementation of Canny Edge Detection is as follow.\n",
    "The algorithm will not be describe thoroughly here.  If you are interested, please refer to the wiki or [here](https://medium.com/@pomelyu5199/canny-edge-detector-%E5%AF%A6%E4%BD%9C-opencv-f7d1a0a57d19).\n",
    "\n",
    "We only need two parameters to implement Canny Edge Detection with CV2:  `low_threshold` and `high_threshold`.\n",
    "\n",
    "```cv2.Canny(image, low_threshold, high_threshold)```\n",
    "\n",
    "Simply put, when the edge value exceeds the high_threshold, we determine it as an edge. If the edge value is only above low_threshold, we will then determine whether it is an edge or not.\n",
    "\n",
    "Let's implement it on the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "mn2MkDLV7E2-",
    "outputId": "99414b46-b70a-4d39-81d3-666e28835596"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
    "plt.figure(figsize=(18, 18))\n",
    "\n",
    "original_img = plt.imread(f'real_or_drawing/train_data/0/0.bmp')\n",
    "plt.subplot(1, 5, 1)\n",
    "no_axis_show(original_img, title='original')\n",
    "\n",
    "gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
    "plt.subplot(1, 5, 2)\n",
    "no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
    "\n",
    "gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
    "plt.subplot(1, 5, 2)\n",
    "no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
    "\n",
    "canny_50100 = cv2.Canny(gray_img, 50, 100)\n",
    "plt.subplot(1, 5, 3)\n",
    "no_axis_show(canny_50100, title='Canny(50, 100)', cmap='gray')\n",
    "\n",
    "canny_150200 = cv2.Canny(gray_img, 150, 200)\n",
    "plt.subplot(1, 5, 4)\n",
    "no_axis_show(canny_150200, title='Canny(150, 200)', cmap='gray')\n",
    "\n",
    "canny_250300 = cv2.Canny(gray_img, 250, 300)\n",
    "plt.subplot(1, 5, 5)\n",
    "no_axis_show(canny_250300, title='Canny(250, 300)', cmap='gray')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8THSdt_hmwYh"
   },
   "source": [
    "# Data Process\n",
    " \n",
    " \n",
    "The data is suitible for `torchvision.ImageFolder`. You can create a dataset with `torchvision.ImageFolder`. Details for image augmentation please refer to the comments in the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "WZHIBGknmi8Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    " \n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "source_transform = transforms.Compose([\n",
    "    # Turn RGB to grayscale. (Bacause Canny do not support RGB images.)\n",
    "    transforms.Grayscale(),\n",
    "    # cv2 do not support skimage.Image, so we transform it to np.array, \n",
    "    # and then adopt cv2.Canny algorithm.\n",
    "    transforms.Lambda(lambda x: cv2.Canny(np.array(x), 170, 300)),\n",
    "    # Transform np.array back to the skimage.Image.\n",
    "    transforms.ToPILImage(),\n",
    "    # 50% Horizontal Flip. (For Augmentation)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
    "    # if there's empty pixel after rotation.\n",
    "    transforms.RandomRotation(15, fill=(0,)),\n",
    "    # Transform to tensor for model inputs.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    # Turn RGB to grayscale.\n",
    "    transforms.Grayscale(),\n",
    "    # Resize: size of source data is 32x32, thus we need to \n",
    "    #  enlarge the size of target data from 28x28 to 32x32。\n",
    "    transforms.Resize((32, 32)),\n",
    "    # 50% Horizontal Flip. (For Augmentation)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
    "    # if there's empty pixel after rotation.\n",
    "    transforms.RandomRotation(15, fill=(0,)),\n",
    "    # Transform to tensor for model inputs.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    " \n",
    "source_dataset = ImageFolder('real_or_drawing/train_data', transform=source_transform)\n",
    "target_dataset = ImageFolder('real_or_drawing/test_data', transform=target_transform)\n",
    " \n",
    "source_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdwDEMrOycs5"
   },
   "source": [
    "# Model\n",
    "\n",
    "Feature Extractor: Classic VGG-like architecture\n",
    "\n",
    "Label Predictor / Domain Classifier: Linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "3uw2eP09z-pD"
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x).squeeze()\n",
    "        return x\n",
    "\n",
    "class LabelPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        c = self.layer(h)\n",
    "        return c\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        y = self.layer(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxdBIPhF0Icb"
   },
   "source": [
    "# Pre-processing\n",
    "\n",
    "Here we use Adam as our optimizor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hrxKelBy0PJ7"
   },
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor().cuda()\n",
    "label_predictor = LabelPredictor().cuda()\n",
    "domain_classifier = DomainClassifier().cuda()\n",
    "\n",
    "class_criterion = nn.CrossEntropyLoss()\n",
    "domain_criterion = nn.BCEWithLogitsLoss() #BCEloss 二分类交叉熵\n",
    "\n",
    "optimizer_F = optim.Adam(feature_extractor.parameters())\n",
    "optimizer_C = optim.Adam(label_predictor.parameters())\n",
    "optimizer_D = optim.Adam(domain_classifier.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuAE4cqJ0itR"
   },
   "source": [
    "# Start Training\n",
    "\n",
    "\n",
    "## DaNN Implementation\n",
    "\n",
    "In the original paper, Gradient Reversal Layer is used.\n",
    "Feature Extractor, Label Predictor, and Domain Classifier are all trained at the same time. In this code, we train Domain Classifier first, and then train our Feature Extractor (same concept as Generator and Discriminator training process in GAN).\n",
    "\n",
    "## Reminder\n",
    "* Lambda, which controls the domain adversarial loss, is adaptive in the original paper. You can refer to [the original work](https://arxiv.org/pdf/1505.07818.pdf) . Here lambda is set to 0.1.\n",
    "* We do not have the label to target data, you can only evaluate your model by uploading your result to kaggle.:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lRAFFKvX0p9y",
    "outputId": "eb1a0cd7-e2fd-49c2-e6c2-28d90b87a813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0: train D loss: 0.7047, train F loss: 1.9101, acc 0.2636 lambda 0.1000\n",
      "epoch   1: train D loss: 0.5969, train F loss: 1.5772, acc 0.4092 lambda 0.1037\n",
      "epoch   2: train D loss: 0.5703, train F loss: 1.4518, acc 0.4648 lambda 0.1075\n",
      "epoch   3: train D loss: 0.5475, train F loss: 1.3612, acc 0.5046 lambda 0.1112\n",
      "epoch   4: train D loss: 0.5400, train F loss: 1.3129, acc 0.5182 lambda 0.1150\n",
      "epoch   5: train D loss: 0.5446, train F loss: 1.2584, acc 0.5386 lambda 0.1187\n",
      "epoch   6: train D loss: 0.5479, train F loss: 1.2186, acc 0.5572 lambda 0.1225\n",
      "epoch   7: train D loss: 0.5487, train F loss: 1.1648, acc 0.5654 lambda 0.1262\n",
      "epoch   8: train D loss: 0.5663, train F loss: 1.1258, acc 0.5828 lambda 0.1300\n",
      "epoch   9: train D loss: 0.5634, train F loss: 1.0890, acc 0.5962 lambda 0.1337\n",
      "epoch  10: train D loss: 0.5502, train F loss: 1.0720, acc 0.5956 lambda 0.1375\n",
      "epoch  11: train D loss: 0.5832, train F loss: 1.0159, acc 0.6226 lambda 0.1412\n",
      "epoch  12: train D loss: 0.5428, train F loss: 0.9902, acc 0.6248 lambda 0.1449\n",
      "epoch  13: train D loss: 0.5661, train F loss: 0.9363, acc 0.6450 lambda 0.1486\n",
      "epoch  14: train D loss: 0.5736, train F loss: 0.9266, acc 0.6446 lambda 0.1524\n",
      "epoch  15: train D loss: 0.5647, train F loss: 0.8714, acc 0.6666 lambda 0.1561\n",
      "epoch  16: train D loss: 0.5741, train F loss: 0.8337, acc 0.6806 lambda 0.1598\n",
      "epoch  17: train D loss: 0.5760, train F loss: 0.7947, acc 0.6898 lambda 0.1635\n",
      "epoch  18: train D loss: 0.5776, train F loss: 0.7674, acc 0.7048 lambda 0.1672\n",
      "epoch  19: train D loss: 0.5707, train F loss: 0.7392, acc 0.7132 lambda 0.1709\n",
      "epoch  20: train D loss: 0.5706, train F loss: 0.6889, acc 0.7228 lambda 0.1746\n",
      "epoch  21: train D loss: 0.5524, train F loss: 0.6621, acc 0.7388 lambda 0.1783\n",
      "epoch  22: train D loss: 0.5872, train F loss: 0.6369, acc 0.7404 lambda 0.1820\n",
      "epoch  23: train D loss: 0.5594, train F loss: 0.6068, acc 0.7566 lambda 0.1857\n",
      "epoch  24: train D loss: 0.5558, train F loss: 0.5553, acc 0.7788 lambda 0.1893\n",
      "epoch  25: train D loss: 0.5589, train F loss: 0.5355, acc 0.7724 lambda 0.1930\n",
      "epoch  26: train D loss: 0.5586, train F loss: 0.5258, acc 0.7886 lambda 0.1967\n",
      "epoch  27: train D loss: 0.5403, train F loss: 0.4889, acc 0.7938 lambda 0.2003\n",
      "epoch  28: train D loss: 0.5690, train F loss: 0.4353, acc 0.8044 lambda 0.2039\n",
      "epoch  29: train D loss: 0.5746, train F loss: 0.4142, acc 0.8184 lambda 0.2076\n",
      "epoch  30: train D loss: 0.5466, train F loss: 0.3992, acc 0.8312 lambda 0.2112\n",
      "epoch  31: train D loss: 0.5593, train F loss: 0.3771, acc 0.8316 lambda 0.2148\n",
      "epoch  32: train D loss: 0.5659, train F loss: 0.3656, acc 0.8420 lambda 0.2184\n",
      "epoch  33: train D loss: 0.5318, train F loss: 0.3265, acc 0.8432 lambda 0.2220\n",
      "epoch  34: train D loss: 0.5756, train F loss: 0.3135, acc 0.8486 lambda 0.2256\n",
      "epoch  35: train D loss: 0.5559, train F loss: 0.2708, acc 0.8696 lambda 0.2292\n",
      "epoch  36: train D loss: 0.5668, train F loss: 0.2666, acc 0.8672 lambda 0.2328\n",
      "epoch  37: train D loss: 0.5583, train F loss: 0.2244, acc 0.8818 lambda 0.2363\n",
      "epoch  38: train D loss: 0.5682, train F loss: 0.1962, acc 0.8878 lambda 0.2399\n",
      "epoch  39: train D loss: 0.5611, train F loss: 0.2029, acc 0.8844 lambda 0.2434\n",
      "epoch  40: train D loss: 0.5646, train F loss: 0.1777, acc 0.8948 lambda 0.2470\n",
      "epoch  41: train D loss: 0.5693, train F loss: 0.1783, acc 0.8916 lambda 0.2505\n",
      "epoch  42: train D loss: 0.5498, train F loss: 0.1794, acc 0.8976 lambda 0.2540\n",
      "epoch  43: train D loss: 0.5568, train F loss: 0.1428, acc 0.9068 lambda 0.2575\n",
      "epoch  44: train D loss: 0.5711, train F loss: 0.1313, acc 0.9070 lambda 0.2610\n",
      "epoch  45: train D loss: 0.5795, train F loss: 0.1420, acc 0.9010 lambda 0.2644\n",
      "epoch  46: train D loss: 0.5570, train F loss: 0.1111, acc 0.9162 lambda 0.2679\n",
      "epoch  47: train D loss: 0.5789, train F loss: 0.0938, acc 0.9184 lambda 0.2713\n",
      "epoch  48: train D loss: 0.5670, train F loss: 0.0945, acc 0.9158 lambda 0.2748\n",
      "epoch  49: train D loss: 0.5753, train F loss: 0.0914, acc 0.9194 lambda 0.2782\n",
      "epoch  50: train D loss: 0.5677, train F loss: 0.0680, acc 0.9252 lambda 0.2816\n",
      "epoch  51: train D loss: 0.5580, train F loss: 0.0443, acc 0.9342 lambda 0.2850\n",
      "epoch  52: train D loss: 0.5637, train F loss: 0.0599, acc 0.9256 lambda 0.2884\n",
      "epoch  53: train D loss: 0.5693, train F loss: 0.0797, acc 0.9212 lambda 0.2918\n",
      "epoch  54: train D loss: 0.5747, train F loss: 0.0371, acc 0.9346 lambda 0.2951\n",
      "epoch  55: train D loss: 0.5689, train F loss: 0.0345, acc 0.9364 lambda 0.2985\n",
      "epoch  56: train D loss: 0.5855, train F loss: 0.0333, acc 0.9308 lambda 0.3018\n",
      "epoch  57: train D loss: 0.5718, train F loss: 0.0206, acc 0.9384 lambda 0.3051\n",
      "epoch  58: train D loss: 0.5870, train F loss: 0.0200, acc 0.9384 lambda 0.3084\n",
      "epoch  59: train D loss: 0.5823, train F loss: 0.0070, acc 0.9372 lambda 0.3117\n",
      "epoch  60: train D loss: 0.5656, train F loss: 0.0123, acc 0.9396 lambda 0.3150\n",
      "epoch  61: train D loss: 0.5845, train F loss: -0.0284, acc 0.9504 lambda 0.3183\n",
      "epoch  62: train D loss: 0.5719, train F loss: -0.0055, acc 0.9470 lambda 0.3215\n",
      "epoch  63: train D loss: 0.5751, train F loss: -0.0271, acc 0.9508 lambda 0.3248\n",
      "epoch  64: train D loss: 0.5765, train F loss: -0.0017, acc 0.9380 lambda 0.3280\n",
      "epoch  65: train D loss: 0.5998, train F loss: -0.0362, acc 0.9484 lambda 0.3312\n",
      "epoch  66: train D loss: 0.5931, train F loss: -0.0144, acc 0.9428 lambda 0.3344\n",
      "epoch  67: train D loss: 0.5782, train F loss: -0.0384, acc 0.9538 lambda 0.3375\n",
      "epoch  68: train D loss: 0.5932, train F loss: -0.0474, acc 0.9530 lambda 0.3407\n",
      "epoch  69: train D loss: 0.5803, train F loss: -0.0472, acc 0.9518 lambda 0.3438\n",
      "epoch  70: train D loss: 0.6010, train F loss: -0.0445, acc 0.9486 lambda 0.3469\n",
      "epoch  71: train D loss: 0.5942, train F loss: -0.0194, acc 0.9400 lambda 0.3500\n",
      "epoch  72: train D loss: 0.5769, train F loss: -0.0392, acc 0.9480 lambda 0.3531\n",
      "epoch  73: train D loss: 0.5973, train F loss: -0.0537, acc 0.9502 lambda 0.3562\n",
      "epoch  74: train D loss: 0.5813, train F loss: -0.0570, acc 0.9504 lambda 0.3593\n",
      "epoch  75: train D loss: 0.5973, train F loss: -0.0730, acc 0.9556 lambda 0.3623\n",
      "epoch  76: train D loss: 0.5872, train F loss: -0.0595, acc 0.9498 lambda 0.3653\n",
      "epoch  77: train D loss: 0.5843, train F loss: -0.0759, acc 0.9570 lambda 0.3683\n",
      "epoch  78: train D loss: 0.5990, train F loss: -0.0637, acc 0.9486 lambda 0.3713\n",
      "epoch  79: train D loss: 0.5910, train F loss: -0.0869, acc 0.9578 lambda 0.3743\n",
      "epoch  80: train D loss: 0.5921, train F loss: -0.0727, acc 0.9528 lambda 0.3773\n",
      "epoch  81: train D loss: 0.5988, train F loss: -0.0883, acc 0.9574 lambda 0.3802\n",
      "epoch  82: train D loss: 0.5882, train F loss: -0.0816, acc 0.9584 lambda 0.3831\n",
      "epoch  83: train D loss: 0.6036, train F loss: -0.0918, acc 0.9552 lambda 0.3860\n",
      "epoch  84: train D loss: 0.6050, train F loss: -0.1048, acc 0.9606 lambda 0.3889\n",
      "epoch  85: train D loss: 0.6039, train F loss: -0.0921, acc 0.9550 lambda 0.3918\n",
      "epoch  86: train D loss: 0.6020, train F loss: -0.1026, acc 0.9574 lambda 0.3947\n",
      "epoch  87: train D loss: 0.6086, train F loss: -0.1037, acc 0.9594 lambda 0.3975\n",
      "epoch  88: train D loss: 0.5867, train F loss: -0.1161, acc 0.9654 lambda 0.4003\n",
      "epoch  89: train D loss: 0.6115, train F loss: -0.1008, acc 0.9536 lambda 0.4031\n",
      "epoch  90: train D loss: 0.5998, train F loss: -0.1242, acc 0.9656 lambda 0.4059\n",
      "epoch  91: train D loss: 0.6113, train F loss: -0.1305, acc 0.9628 lambda 0.4087\n",
      "epoch  92: train D loss: 0.5999, train F loss: -0.0968, acc 0.9524 lambda 0.4114\n",
      "epoch  93: train D loss: 0.6017, train F loss: -0.1145, acc 0.9600 lambda 0.4141\n",
      "epoch  94: train D loss: 0.5995, train F loss: -0.1108, acc 0.9602 lambda 0.4169\n",
      "epoch  95: train D loss: 0.6102, train F loss: -0.1318, acc 0.9642 lambda 0.4196\n",
      "epoch  96: train D loss: 0.6093, train F loss: -0.1380, acc 0.9628 lambda 0.4222\n",
      "epoch  97: train D loss: 0.6142, train F loss: -0.1583, acc 0.9686 lambda 0.4249\n",
      "epoch  98: train D loss: 0.6041, train F loss: -0.1216, acc 0.9604 lambda 0.4275\n",
      "epoch  99: train D loss: 0.6103, train F loss: -0.1363, acc 0.9612 lambda 0.4302\n",
      "epoch 100: train D loss: 0.6020, train F loss: -0.1215, acc 0.9596 lambda 0.4328\n",
      "epoch 101: train D loss: 0.6192, train F loss: -0.1368, acc 0.9572 lambda 0.4353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102: train D loss: 0.6118, train F loss: -0.1473, acc 0.9620 lambda 0.4379\n",
      "epoch 103: train D loss: 0.6081, train F loss: -0.1648, acc 0.9686 lambda 0.4405\n",
      "epoch 104: train D loss: 0.6139, train F loss: -0.1540, acc 0.9626 lambda 0.4430\n",
      "epoch 105: train D loss: 0.6156, train F loss: -0.1581, acc 0.9614 lambda 0.4455\n",
      "epoch 106: train D loss: 0.6116, train F loss: -0.1538, acc 0.9652 lambda 0.4480\n",
      "epoch 107: train D loss: 0.6164, train F loss: -0.1478, acc 0.9606 lambda 0.4505\n",
      "epoch 108: train D loss: 0.6199, train F loss: -0.1575, acc 0.9620 lambda 0.4530\n",
      "epoch 109: train D loss: 0.6127, train F loss: -0.1620, acc 0.9650 lambda 0.4554\n",
      "epoch 110: train D loss: 0.6105, train F loss: -0.1801, acc 0.9710 lambda 0.4578\n",
      "epoch 111: train D loss: 0.6073, train F loss: -0.1689, acc 0.9656 lambda 0.4602\n",
      "epoch 112: train D loss: 0.6121, train F loss: -0.1793, acc 0.9698 lambda 0.4626\n",
      "epoch 113: train D loss: 0.6157, train F loss: -0.1723, acc 0.9668 lambda 0.4650\n",
      "epoch 114: train D loss: 0.6193, train F loss: -0.1772, acc 0.9632 lambda 0.4673\n",
      "epoch 115: train D loss: 0.6167, train F loss: -0.1778, acc 0.9650 lambda 0.4697\n",
      "epoch 116: train D loss: 0.6203, train F loss: -0.1918, acc 0.9724 lambda 0.4720\n",
      "epoch 117: train D loss: 0.6138, train F loss: -0.1816, acc 0.9680 lambda 0.4743\n",
      "epoch 118: train D loss: 0.6116, train F loss: -0.1637, acc 0.9604 lambda 0.4766\n",
      "epoch 119: train D loss: 0.6188, train F loss: -0.2008, acc 0.9696 lambda 0.4788\n",
      "epoch 120: train D loss: 0.6071, train F loss: -0.2003, acc 0.9744 lambda 0.4811\n",
      "epoch 121: train D loss: 0.6259, train F loss: -0.1999, acc 0.9682 lambda 0.4833\n",
      "epoch 122: train D loss: 0.6239, train F loss: -0.1982, acc 0.9672 lambda 0.4855\n",
      "epoch 123: train D loss: 0.6157, train F loss: -0.1754, acc 0.9648 lambda 0.4877\n",
      "epoch 124: train D loss: 0.6130, train F loss: -0.1953, acc 0.9676 lambda 0.4899\n",
      "epoch 125: train D loss: 0.6167, train F loss: -0.1982, acc 0.9680 lambda 0.4921\n",
      "epoch 126: train D loss: 0.6228, train F loss: -0.2047, acc 0.9660 lambda 0.4942\n",
      "epoch 127: train D loss: 0.6275, train F loss: -0.2135, acc 0.9714 lambda 0.4963\n",
      "epoch 128: train D loss: 0.6169, train F loss: -0.2116, acc 0.9732 lambda 0.4984\n",
      "epoch 129: train D loss: 0.6218, train F loss: -0.2019, acc 0.9680 lambda 0.5005\n",
      "epoch 130: train D loss: 0.6318, train F loss: -0.2087, acc 0.9686 lambda 0.5026\n",
      "epoch 131: train D loss: 0.6246, train F loss: -0.2037, acc 0.9692 lambda 0.5046\n",
      "epoch 132: train D loss: 0.6256, train F loss: -0.2161, acc 0.9712 lambda 0.5067\n",
      "epoch 133: train D loss: 0.6138, train F loss: -0.2093, acc 0.9724 lambda 0.5087\n",
      "epoch 134: train D loss: 0.6287, train F loss: -0.2153, acc 0.9694 lambda 0.5107\n",
      "epoch 135: train D loss: 0.6182, train F loss: -0.2072, acc 0.9652 lambda 0.5127\n",
      "epoch 136: train D loss: 0.6241, train F loss: -0.2245, acc 0.9704 lambda 0.5146\n",
      "epoch 137: train D loss: 0.6204, train F loss: -0.2128, acc 0.9670 lambda 0.5166\n",
      "epoch 138: train D loss: 0.6267, train F loss: -0.2179, acc 0.9700 lambda 0.5185\n",
      "epoch 139: train D loss: 0.6221, train F loss: -0.2248, acc 0.9702 lambda 0.5204\n",
      "epoch 140: train D loss: 0.6216, train F loss: -0.2277, acc 0.9720 lambda 0.5223\n",
      "epoch 141: train D loss: 0.6332, train F loss: -0.2411, acc 0.9728 lambda 0.5242\n",
      "epoch 142: train D loss: 0.6260, train F loss: -0.2087, acc 0.9654 lambda 0.5261\n",
      "epoch 143: train D loss: 0.6241, train F loss: -0.2282, acc 0.9696 lambda 0.5279\n",
      "epoch 144: train D loss: 0.6324, train F loss: -0.2382, acc 0.9706 lambda 0.5298\n",
      "epoch 145: train D loss: 0.6192, train F loss: -0.2375, acc 0.9730 lambda 0.5316\n",
      "epoch 146: train D loss: 0.6294, train F loss: -0.2519, acc 0.9748 lambda 0.5334\n",
      "epoch 147: train D loss: 0.6324, train F loss: -0.2465, acc 0.9728 lambda 0.5352\n",
      "epoch 148: train D loss: 0.6271, train F loss: -0.2506, acc 0.9724 lambda 0.5370\n",
      "epoch 149: train D loss: 0.6272, train F loss: -0.2406, acc 0.9722 lambda 0.5387\n",
      "epoch 150: train D loss: 0.6321, train F loss: -0.2376, acc 0.9696 lambda 0.5404\n",
      "epoch 151: train D loss: 0.6308, train F loss: -0.2505, acc 0.9744 lambda 0.5422\n",
      "epoch 152: train D loss: 0.6221, train F loss: -0.2636, acc 0.9762 lambda 0.5439\n",
      "epoch 153: train D loss: 0.6302, train F loss: -0.2322, acc 0.9686 lambda 0.5456\n",
      "epoch 154: train D loss: 0.6177, train F loss: -0.2513, acc 0.9746 lambda 0.5472\n",
      "epoch 155: train D loss: 0.6198, train F loss: -0.2573, acc 0.9768 lambda 0.5489\n",
      "epoch 156: train D loss: 0.6303, train F loss: -0.2576, acc 0.9728 lambda 0.5505\n",
      "epoch 157: train D loss: 0.6294, train F loss: -0.2521, acc 0.9724 lambda 0.5522\n",
      "epoch 158: train D loss: 0.6240, train F loss: -0.2415, acc 0.9710 lambda 0.5538\n",
      "epoch 159: train D loss: 0.6351, train F loss: -0.2641, acc 0.9740 lambda 0.5554\n",
      "epoch 160: train D loss: 0.6259, train F loss: -0.2437, acc 0.9674 lambda 0.5570\n",
      "epoch 161: train D loss: 0.6279, train F loss: -0.2725, acc 0.9778 lambda 0.5585\n",
      "epoch 162: train D loss: 0.6247, train F loss: -0.2649, acc 0.9780 lambda 0.5601\n",
      "epoch 163: train D loss: 0.6445, train F loss: -0.2701, acc 0.9746 lambda 0.5616\n",
      "epoch 164: train D loss: 0.6241, train F loss: -0.2664, acc 0.9756 lambda 0.5631\n",
      "epoch 165: train D loss: 0.6405, train F loss: -0.2619, acc 0.9706 lambda 0.5646\n",
      "epoch 166: train D loss: 0.6371, train F loss: -0.2706, acc 0.9732 lambda 0.5661\n",
      "epoch 167: train D loss: 0.6312, train F loss: -0.2662, acc 0.9740 lambda 0.5676\n",
      "epoch 168: train D loss: 0.6297, train F loss: -0.2839, acc 0.9788 lambda 0.5691\n",
      "epoch 169: train D loss: 0.6347, train F loss: -0.2778, acc 0.9744 lambda 0.5705\n",
      "epoch 170: train D loss: 0.6252, train F loss: -0.2802, acc 0.9782 lambda 0.5720\n",
      "epoch 171: train D loss: 0.6344, train F loss: -0.2541, acc 0.9698 lambda 0.5734\n",
      "epoch 172: train D loss: 0.6413, train F loss: -0.2786, acc 0.9740 lambda 0.5748\n",
      "epoch 173: train D loss: 0.6312, train F loss: -0.2888, acc 0.9770 lambda 0.5762\n",
      "epoch 174: train D loss: 0.6299, train F loss: -0.2876, acc 0.9784 lambda 0.5776\n",
      "epoch 175: train D loss: 0.6324, train F loss: -0.2709, acc 0.9706 lambda 0.5789\n",
      "epoch 176: train D loss: 0.6328, train F loss: -0.2726, acc 0.9730 lambda 0.5803\n",
      "epoch 177: train D loss: 0.6338, train F loss: -0.2664, acc 0.9708 lambda 0.5816\n",
      "epoch 178: train D loss: 0.6336, train F loss: -0.2720, acc 0.9726 lambda 0.5830\n",
      "epoch 179: train D loss: 0.6259, train F loss: -0.2736, acc 0.9750 lambda 0.5843\n",
      "epoch 180: train D loss: 0.6337, train F loss: -0.2938, acc 0.9768 lambda 0.5856\n",
      "epoch 181: train D loss: 0.6336, train F loss: -0.2826, acc 0.9726 lambda 0.5869\n",
      "epoch 182: train D loss: 0.6289, train F loss: -0.2842, acc 0.9762 lambda 0.5881\n",
      "epoch 183: train D loss: 0.6301, train F loss: -0.2949, acc 0.9784 lambda 0.5894\n",
      "epoch 184: train D loss: 0.6323, train F loss: -0.2936, acc 0.9780 lambda 0.5907\n",
      "epoch 185: train D loss: 0.6385, train F loss: -0.2999, acc 0.9762 lambda 0.5919\n",
      "epoch 186: train D loss: 0.6325, train F loss: -0.2899, acc 0.9736 lambda 0.5931\n",
      "epoch 187: train D loss: 0.6393, train F loss: -0.2923, acc 0.9726 lambda 0.5943\n",
      "epoch 188: train D loss: 0.6342, train F loss: -0.2982, acc 0.9784 lambda 0.5955\n",
      "epoch 189: train D loss: 0.6320, train F loss: -0.2940, acc 0.9764 lambda 0.5967\n",
      "epoch 190: train D loss: 0.6408, train F loss: -0.3042, acc 0.9790 lambda 0.5979\n",
      "epoch 191: train D loss: 0.6297, train F loss: -0.2832, acc 0.9742 lambda 0.5990\n",
      "epoch 192: train D loss: 0.6377, train F loss: -0.2924, acc 0.9766 lambda 0.6002\n",
      "epoch 193: train D loss: 0.6350, train F loss: -0.2894, acc 0.9744 lambda 0.6013\n",
      "epoch 194: train D loss: 0.6337, train F loss: -0.2993, acc 0.9778 lambda 0.6025\n",
      "epoch 195: train D loss: 0.6345, train F loss: -0.3002, acc 0.9758 lambda 0.6036\n",
      "epoch 196: train D loss: 0.6375, train F loss: -0.3008, acc 0.9756 lambda 0.6047\n",
      "epoch 197: train D loss: 0.6331, train F loss: -0.2972, acc 0.9752 lambda 0.6058\n",
      "epoch 198: train D loss: 0.6419, train F loss: -0.3133, acc 0.9766 lambda 0.6068\n",
      "epoch 199: train D loss: 0.6364, train F loss: -0.3031, acc 0.9768 lambda 0.6079\n",
      "epoch 200: train D loss: 0.6295, train F loss: -0.3129, acc 0.9810 lambda 0.6090\n",
      "epoch 201: train D loss: 0.6372, train F loss: -0.3084, acc 0.9780 lambda 0.6100\n",
      "epoch 202: train D loss: 0.6390, train F loss: -0.3136, acc 0.9788 lambda 0.6111\n",
      "epoch 203: train D loss: 0.6382, train F loss: -0.3243, acc 0.9820 lambda 0.6121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 204: train D loss: 0.6357, train F loss: -0.3080, acc 0.9766 lambda 0.6131\n",
      "epoch 205: train D loss: 0.6423, train F loss: -0.3158, acc 0.9774 lambda 0.6141\n",
      "epoch 206: train D loss: 0.6373, train F loss: -0.3195, acc 0.9800 lambda 0.6151\n",
      "epoch 207: train D loss: 0.6395, train F loss: -0.3147, acc 0.9794 lambda 0.6161\n",
      "epoch 208: train D loss: 0.6392, train F loss: -0.3171, acc 0.9796 lambda 0.6170\n",
      "epoch 209: train D loss: 0.6397, train F loss: -0.3185, acc 0.9784 lambda 0.6180\n",
      "epoch 210: train D loss: 0.6382, train F loss: -0.3154, acc 0.9758 lambda 0.6189\n",
      "epoch 211: train D loss: 0.6376, train F loss: -0.3090, acc 0.9768 lambda 0.6199\n",
      "epoch 212: train D loss: 0.6438, train F loss: -0.3226, acc 0.9806 lambda 0.6208\n",
      "epoch 213: train D loss: 0.6430, train F loss: -0.3159, acc 0.9768 lambda 0.6217\n",
      "epoch 214: train D loss: 0.6427, train F loss: -0.3208, acc 0.9770 lambda 0.6226\n",
      "epoch 215: train D loss: 0.6426, train F loss: -0.3279, acc 0.9792 lambda 0.6235\n",
      "epoch 216: train D loss: 0.6403, train F loss: -0.3284, acc 0.9792 lambda 0.6244\n",
      "epoch 217: train D loss: 0.6454, train F loss: -0.3293, acc 0.9794 lambda 0.6253\n",
      "epoch 218: train D loss: 0.6294, train F loss: -0.3178, acc 0.9748 lambda 0.6262\n",
      "epoch 219: train D loss: 0.6451, train F loss: -0.3286, acc 0.9778 lambda 0.6270\n",
      "epoch 220: train D loss: 0.6414, train F loss: -0.3242, acc 0.9770 lambda 0.6279\n",
      "epoch 221: train D loss: 0.6445, train F loss: -0.3317, acc 0.9766 lambda 0.6287\n",
      "epoch 222: train D loss: 0.6308, train F loss: -0.3247, acc 0.9800 lambda 0.6296\n",
      "epoch 223: train D loss: 0.6381, train F loss: -0.3244, acc 0.9806 lambda 0.6304\n",
      "epoch 224: train D loss: 0.6418, train F loss: -0.3295, acc 0.9756 lambda 0.6312\n",
      "epoch 225: train D loss: 0.6417, train F loss: -0.3395, acc 0.9810 lambda 0.6320\n",
      "epoch 226: train D loss: 0.6461, train F loss: -0.3340, acc 0.9804 lambda 0.6328\n",
      "epoch 227: train D loss: 0.6329, train F loss: -0.3188, acc 0.9768 lambda 0.6336\n",
      "epoch 228: train D loss: 0.6372, train F loss: -0.3342, acc 0.9798 lambda 0.6344\n",
      "epoch 229: train D loss: 0.6407, train F loss: -0.3267, acc 0.9770 lambda 0.6352\n",
      "epoch 230: train D loss: 0.6444, train F loss: -0.3329, acc 0.9766 lambda 0.6359\n",
      "epoch 231: train D loss: 0.6446, train F loss: -0.3470, acc 0.9826 lambda 0.6367\n",
      "epoch 232: train D loss: 0.6384, train F loss: -0.3357, acc 0.9796 lambda 0.6374\n",
      "epoch 233: train D loss: 0.6447, train F loss: -0.3350, acc 0.9778 lambda 0.6382\n",
      "epoch 234: train D loss: 0.6404, train F loss: -0.3280, acc 0.9790 lambda 0.6389\n",
      "epoch 235: train D loss: 0.6486, train F loss: -0.3455, acc 0.9826 lambda 0.6396\n",
      "epoch 236: train D loss: 0.6417, train F loss: -0.3479, acc 0.9826 lambda 0.6403\n",
      "epoch 237: train D loss: 0.6523, train F loss: -0.3609, acc 0.9830 lambda 0.6410\n",
      "epoch 238: train D loss: 0.6449, train F loss: -0.3463, acc 0.9806 lambda 0.6417\n",
      "epoch 239: train D loss: 0.6401, train F loss: -0.3259, acc 0.9730 lambda 0.6424\n",
      "epoch 240: train D loss: 0.6451, train F loss: -0.3551, acc 0.9834 lambda 0.6431\n",
      "epoch 241: train D loss: 0.6446, train F loss: -0.3367, acc 0.9796 lambda 0.6438\n",
      "epoch 242: train D loss: 0.6486, train F loss: -0.3542, acc 0.9800 lambda 0.6444\n",
      "epoch 243: train D loss: 0.6405, train F loss: -0.3351, acc 0.9786 lambda 0.6451\n",
      "epoch 244: train D loss: 0.6509, train F loss: -0.3499, acc 0.9790 lambda 0.6457\n",
      "epoch 245: train D loss: 0.6471, train F loss: -0.3511, acc 0.9800 lambda 0.6464\n",
      "epoch 246: train D loss: 0.6444, train F loss: -0.3463, acc 0.9790 lambda 0.6470\n",
      "epoch 247: train D loss: 0.6519, train F loss: -0.3342, acc 0.9760 lambda 0.6476\n",
      "epoch 248: train D loss: 0.6419, train F loss: -0.3492, acc 0.9808 lambda 0.6483\n",
      "epoch 249: train D loss: 0.6572, train F loss: -0.3666, acc 0.9828 lambda 0.6489\n",
      "epoch 250: train D loss: 0.6470, train F loss: -0.3569, acc 0.9802 lambda 0.6495\n",
      "epoch 251: train D loss: 0.6554, train F loss: -0.3611, acc 0.9816 lambda 0.6501\n",
      "epoch 252: train D loss: 0.6523, train F loss: -0.3482, acc 0.9778 lambda 0.6507\n",
      "epoch 253: train D loss: 0.6492, train F loss: -0.3536, acc 0.9822 lambda 0.6513\n",
      "epoch 254: train D loss: 0.6437, train F loss: -0.3549, acc 0.9820 lambda 0.6519\n",
      "epoch 255: train D loss: 0.6426, train F loss: -0.3444, acc 0.9806 lambda 0.6524\n",
      "epoch 256: train D loss: 0.6480, train F loss: -0.3627, acc 0.9838 lambda 0.6530\n",
      "epoch 257: train D loss: 0.6523, train F loss: -0.3533, acc 0.9788 lambda 0.6536\n",
      "epoch 258: train D loss: 0.6403, train F loss: -0.3559, acc 0.9814 lambda 0.6541\n",
      "epoch 259: train D loss: 0.6466, train F loss: -0.3519, acc 0.9822 lambda 0.6547\n",
      "epoch 260: train D loss: 0.6465, train F loss: -0.3486, acc 0.9792 lambda 0.6552\n",
      "epoch 261: train D loss: 0.6505, train F loss: -0.3566, acc 0.9800 lambda 0.6557\n",
      "epoch 262: train D loss: 0.6394, train F loss: -0.3530, acc 0.9804 lambda 0.6563\n",
      "epoch 263: train D loss: 0.6387, train F loss: -0.3557, acc 0.9834 lambda 0.6568\n",
      "epoch 264: train D loss: 0.6404, train F loss: -0.3557, acc 0.9826 lambda 0.6573\n",
      "epoch 265: train D loss: 0.6432, train F loss: -0.3453, acc 0.9782 lambda 0.6578\n",
      "epoch 266: train D loss: 0.6475, train F loss: -0.3660, acc 0.9840 lambda 0.6583\n",
      "epoch 267: train D loss: 0.6429, train F loss: -0.3497, acc 0.9792 lambda 0.6588\n",
      "epoch 268: train D loss: 0.6434, train F loss: -0.3634, acc 0.9844 lambda 0.6593\n",
      "epoch 269: train D loss: 0.6468, train F loss: -0.3578, acc 0.9822 lambda 0.6598\n",
      "epoch 270: train D loss: 0.6414, train F loss: -0.3413, acc 0.9782 lambda 0.6603\n",
      "epoch 271: train D loss: 0.6480, train F loss: -0.3528, acc 0.9798 lambda 0.6608\n",
      "epoch 272: train D loss: 0.6415, train F loss: -0.3430, acc 0.9764 lambda 0.6612\n",
      "epoch 273: train D loss: 0.6404, train F loss: -0.3462, acc 0.9778 lambda 0.6617\n",
      "epoch 274: train D loss: 0.6419, train F loss: -0.3700, acc 0.9860 lambda 0.6622\n",
      "epoch 275: train D loss: 0.6448, train F loss: -0.3500, acc 0.9784 lambda 0.6626\n",
      "epoch 276: train D loss: 0.6454, train F loss: -0.3702, acc 0.9848 lambda 0.6631\n",
      "epoch 277: train D loss: 0.6533, train F loss: -0.3659, acc 0.9774 lambda 0.6635\n",
      "epoch 278: train D loss: 0.6469, train F loss: -0.3718, acc 0.9850 lambda 0.6640\n",
      "epoch 279: train D loss: 0.6514, train F loss: -0.3589, acc 0.9784 lambda 0.6644\n",
      "epoch 280: train D loss: 0.6475, train F loss: -0.3643, acc 0.9846 lambda 0.6648\n",
      "epoch 281: train D loss: 0.6507, train F loss: -0.3523, acc 0.9784 lambda 0.6652\n",
      "epoch 282: train D loss: 0.6500, train F loss: -0.3665, acc 0.9808 lambda 0.6657\n",
      "epoch 283: train D loss: 0.6500, train F loss: -0.3663, acc 0.9810 lambda 0.6661\n",
      "epoch 284: train D loss: 0.6521, train F loss: -0.3623, acc 0.9810 lambda 0.6665\n",
      "epoch 285: train D loss: 0.6533, train F loss: -0.3717, acc 0.9814 lambda 0.6669\n",
      "epoch 286: train D loss: 0.6464, train F loss: -0.3748, acc 0.9850 lambda 0.6673\n",
      "epoch 287: train D loss: 0.6558, train F loss: -0.3712, acc 0.9826 lambda 0.6677\n",
      "epoch 288: train D loss: 0.6460, train F loss: -0.3519, acc 0.9778 lambda 0.6681\n",
      "epoch 289: train D loss: 0.6455, train F loss: -0.3674, acc 0.9824 lambda 0.6685\n",
      "epoch 290: train D loss: 0.6490, train F loss: -0.3806, acc 0.9838 lambda 0.6689\n",
      "epoch 291: train D loss: 0.6509, train F loss: -0.3641, acc 0.9806 lambda 0.6692\n",
      "epoch 292: train D loss: 0.6486, train F loss: -0.3569, acc 0.9810 lambda 0.6696\n",
      "epoch 293: train D loss: 0.6398, train F loss: -0.3620, acc 0.9824 lambda 0.6700\n",
      "epoch 294: train D loss: 0.6457, train F loss: -0.3624, acc 0.9806 lambda 0.6703\n",
      "epoch 295: train D loss: 0.6405, train F loss: -0.3594, acc 0.9818 lambda 0.6707\n",
      "epoch 296: train D loss: 0.6523, train F loss: -0.3729, acc 0.9814 lambda 0.6710\n",
      "epoch 297: train D loss: 0.6525, train F loss: -0.3658, acc 0.9812 lambda 0.6714\n",
      "epoch 298: train D loss: 0.6404, train F loss: -0.3666, acc 0.9824 lambda 0.6717\n",
      "epoch 299: train D loss: 0.6409, train F loss: -0.3753, acc 0.9840 lambda 0.6721\n",
      "epoch 300: train D loss: 0.6440, train F loss: -0.3706, acc 0.9820 lambda 0.6724\n",
      "epoch 301: train D loss: 0.6493, train F loss: -0.3652, acc 0.9796 lambda 0.6728\n",
      "epoch 302: train D loss: 0.6489, train F loss: -0.3644, acc 0.9774 lambda 0.6731\n",
      "epoch 303: train D loss: 0.6447, train F loss: -0.3725, acc 0.9838 lambda 0.6734\n",
      "epoch 304: train D loss: 0.6502, train F loss: -0.3672, acc 0.9812 lambda 0.6737\n",
      "epoch 305: train D loss: 0.6490, train F loss: -0.3699, acc 0.9788 lambda 0.6741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 306: train D loss: 0.6504, train F loss: -0.3835, acc 0.9844 lambda 0.6744\n",
      "epoch 307: train D loss: 0.6564, train F loss: -0.3677, acc 0.9806 lambda 0.6747\n",
      "epoch 308: train D loss: 0.6537, train F loss: -0.3785, acc 0.9824 lambda 0.6750\n",
      "epoch 309: train D loss: 0.6492, train F loss: -0.3751, acc 0.9822 lambda 0.6753\n",
      "epoch 310: train D loss: 0.6488, train F loss: -0.3796, acc 0.9824 lambda 0.6756\n",
      "epoch 311: train D loss: 0.6473, train F loss: -0.3738, acc 0.9816 lambda 0.6759\n",
      "epoch 312: train D loss: 0.6481, train F loss: -0.3754, acc 0.9834 lambda 0.6762\n",
      "epoch 313: train D loss: 0.6488, train F loss: -0.3759, acc 0.9816 lambda 0.6765\n",
      "epoch 314: train D loss: 0.6489, train F loss: -0.3835, acc 0.9850 lambda 0.6768\n",
      "epoch 315: train D loss: 0.6552, train F loss: -0.3753, acc 0.9812 lambda 0.6771\n",
      "epoch 316: train D loss: 0.6485, train F loss: -0.3705, acc 0.9826 lambda 0.6773\n",
      "epoch 317: train D loss: 0.6469, train F loss: -0.3794, acc 0.9836 lambda 0.6776\n",
      "epoch 318: train D loss: 0.6492, train F loss: -0.3676, acc 0.9812 lambda 0.6779\n",
      "epoch 319: train D loss: 0.6493, train F loss: -0.3759, acc 0.9830 lambda 0.6782\n",
      "epoch 320: train D loss: 0.6527, train F loss: -0.3844, acc 0.9852 lambda 0.6784\n",
      "epoch 321: train D loss: 0.6488, train F loss: -0.3655, acc 0.9814 lambda 0.6787\n",
      "epoch 322: train D loss: 0.6523, train F loss: -0.3911, acc 0.9866 lambda 0.6789\n",
      "epoch 323: train D loss: 0.6579, train F loss: -0.3817, acc 0.9780 lambda 0.6792\n",
      "epoch 324: train D loss: 0.6508, train F loss: -0.3760, acc 0.9808 lambda 0.6795\n",
      "epoch 325: train D loss: 0.6482, train F loss: -0.3860, acc 0.9854 lambda 0.6797\n",
      "epoch 326: train D loss: 0.6479, train F loss: -0.3763, acc 0.9820 lambda 0.6800\n",
      "epoch 327: train D loss: 0.6549, train F loss: -0.3813, acc 0.9818 lambda 0.6802\n",
      "epoch 328: train D loss: 0.6486, train F loss: -0.3850, acc 0.9844 lambda 0.6804\n",
      "epoch 329: train D loss: 0.6528, train F loss: -0.3933, acc 0.9874 lambda 0.6807\n",
      "epoch 330: train D loss: 0.6452, train F loss: -0.3787, acc 0.9844 lambda 0.6809\n",
      "epoch 331: train D loss: 0.6481, train F loss: -0.3790, acc 0.9822 lambda 0.6811\n",
      "epoch 332: train D loss: 0.6504, train F loss: -0.3863, acc 0.9850 lambda 0.6814\n",
      "epoch 333: train D loss: 0.6495, train F loss: -0.3874, acc 0.9850 lambda 0.6816\n",
      "epoch 334: train D loss: 0.6556, train F loss: -0.3864, acc 0.9820 lambda 0.6818\n",
      "epoch 335: train D loss: 0.6483, train F loss: -0.3847, acc 0.9850 lambda 0.6821\n",
      "epoch 336: train D loss: 0.6570, train F loss: -0.3930, acc 0.9844 lambda 0.6823\n",
      "epoch 337: train D loss: 0.6473, train F loss: -0.3875, acc 0.9852 lambda 0.6825\n",
      "epoch 338: train D loss: 0.6486, train F loss: -0.3811, acc 0.9828 lambda 0.6827\n",
      "epoch 339: train D loss: 0.6514, train F loss: -0.3786, acc 0.9820 lambda 0.6829\n",
      "epoch 340: train D loss: 0.6482, train F loss: -0.3778, acc 0.9848 lambda 0.6831\n",
      "epoch 341: train D loss: 0.6479, train F loss: -0.3789, acc 0.9802 lambda 0.6833\n",
      "epoch 342: train D loss: 0.6479, train F loss: -0.3739, acc 0.9820 lambda 0.6835\n",
      "epoch 343: train D loss: 0.6514, train F loss: -0.3899, acc 0.9850 lambda 0.6837\n",
      "epoch 344: train D loss: 0.6462, train F loss: -0.3749, acc 0.9798 lambda 0.6839\n",
      "epoch 345: train D loss: 0.6512, train F loss: -0.3962, acc 0.9868 lambda 0.6841\n",
      "epoch 346: train D loss: 0.6514, train F loss: -0.3868, acc 0.9846 lambda 0.6843\n",
      "epoch 347: train D loss: 0.6469, train F loss: -0.3868, acc 0.9838 lambda 0.6845\n",
      "epoch 348: train D loss: 0.6494, train F loss: -0.3901, acc 0.9844 lambda 0.6847\n",
      "epoch 349: train D loss: 0.6518, train F loss: -0.3839, acc 0.9812 lambda 0.6849\n",
      "epoch 350: train D loss: 0.6460, train F loss: -0.3847, acc 0.9834 lambda 0.6851\n",
      "epoch 351: train D loss: 0.6454, train F loss: -0.3831, acc 0.9826 lambda 0.6853\n",
      "epoch 352: train D loss: 0.6452, train F loss: -0.3938, acc 0.9860 lambda 0.6854\n",
      "epoch 353: train D loss: 0.6527, train F loss: -0.3851, acc 0.9828 lambda 0.6856\n",
      "epoch 354: train D loss: 0.6428, train F loss: -0.3825, acc 0.9836 lambda 0.6858\n",
      "epoch 355: train D loss: 0.6499, train F loss: -0.3791, acc 0.9808 lambda 0.6860\n",
      "epoch 356: train D loss: 0.6449, train F loss: -0.3782, acc 0.9858 lambda 0.6861\n",
      "epoch 357: train D loss: 0.6601, train F loss: -0.4094, acc 0.9876 lambda 0.6863\n",
      "epoch 358: train D loss: 0.6502, train F loss: -0.3873, acc 0.9838 lambda 0.6865\n",
      "epoch 359: train D loss: 0.6526, train F loss: -0.3953, acc 0.9840 lambda 0.6867\n",
      "epoch 360: train D loss: 0.6543, train F loss: -0.3963, acc 0.9838 lambda 0.6868\n",
      "epoch 361: train D loss: 0.6518, train F loss: -0.3933, acc 0.9838 lambda 0.6870\n",
      "epoch 362: train D loss: 0.6509, train F loss: -0.3999, acc 0.9868 lambda 0.6871\n",
      "epoch 363: train D loss: 0.6535, train F loss: -0.3972, acc 0.9844 lambda 0.6873\n",
      "epoch 364: train D loss: 0.6503, train F loss: -0.3950, acc 0.9854 lambda 0.6875\n",
      "epoch 365: train D loss: 0.6515, train F loss: -0.3998, acc 0.9870 lambda 0.6876\n",
      "epoch 366: train D loss: 0.6533, train F loss: -0.3853, acc 0.9812 lambda 0.6878\n",
      "epoch 367: train D loss: 0.6514, train F loss: -0.3994, acc 0.9856 lambda 0.6879\n",
      "epoch 368: train D loss: 0.6574, train F loss: -0.3795, acc 0.9816 lambda 0.6881\n",
      "epoch 369: train D loss: 0.6522, train F loss: -0.3679, acc 0.9790 lambda 0.6882\n",
      "epoch 370: train D loss: 0.6418, train F loss: -0.3738, acc 0.9832 lambda 0.6883\n",
      "epoch 371: train D loss: 0.6543, train F loss: -0.3858, acc 0.9794 lambda 0.6885\n",
      "epoch 372: train D loss: 0.6405, train F loss: -0.3852, acc 0.9846 lambda 0.6886\n",
      "epoch 373: train D loss: 0.6457, train F loss: -0.3873, acc 0.9848 lambda 0.6888\n",
      "epoch 374: train D loss: 0.6569, train F loss: -0.3932, acc 0.9836 lambda 0.6889\n",
      "epoch 375: train D loss: 0.6494, train F loss: -0.3921, acc 0.9848 lambda 0.6890\n",
      "epoch 376: train D loss: 0.6508, train F loss: -0.3869, acc 0.9818 lambda 0.6892\n",
      "epoch 377: train D loss: 0.6505, train F loss: -0.3846, acc 0.9820 lambda 0.6893\n",
      "epoch 378: train D loss: 0.6549, train F loss: -0.3958, acc 0.9848 lambda 0.6894\n",
      "epoch 379: train D loss: 0.6595, train F loss: -0.4038, acc 0.9844 lambda 0.6896\n",
      "epoch 380: train D loss: 0.6433, train F loss: -0.3827, acc 0.9830 lambda 0.6897\n",
      "epoch 381: train D loss: 0.6411, train F loss: -0.3821, acc 0.9834 lambda 0.6898\n",
      "epoch 382: train D loss: 0.6500, train F loss: -0.3794, acc 0.9822 lambda 0.6900\n",
      "epoch 383: train D loss: 0.6392, train F loss: -0.3774, acc 0.9832 lambda 0.6901\n",
      "epoch 384: train D loss: 0.6471, train F loss: -0.3887, acc 0.9846 lambda 0.6902\n",
      "epoch 385: train D loss: 0.6485, train F loss: -0.3966, acc 0.9876 lambda 0.6903\n",
      "epoch 386: train D loss: 0.6471, train F loss: -0.3833, acc 0.9822 lambda 0.6904\n",
      "epoch 387: train D loss: 0.6544, train F loss: -0.3900, acc 0.9832 lambda 0.6906\n",
      "epoch 388: train D loss: 0.6501, train F loss: -0.3911, acc 0.9848 lambda 0.6907\n",
      "epoch 389: train D loss: 0.6519, train F loss: -0.3916, acc 0.9846 lambda 0.6908\n",
      "epoch 390: train D loss: 0.6511, train F loss: -0.3848, acc 0.9824 lambda 0.6909\n",
      "epoch 391: train D loss: 0.6508, train F loss: -0.3993, acc 0.9876 lambda 0.6910\n",
      "epoch 392: train D loss: 0.6502, train F loss: -0.4048, acc 0.9882 lambda 0.6911\n",
      "epoch 393: train D loss: 0.6486, train F loss: -0.3918, acc 0.9830 lambda 0.6912\n",
      "epoch 394: train D loss: 0.6527, train F loss: -0.3874, acc 0.9824 lambda 0.6913\n",
      "epoch 395: train D loss: 0.6513, train F loss: -0.3934, acc 0.9852 lambda 0.6915\n",
      "epoch 396: train D loss: 0.6471, train F loss: -0.3987, acc 0.9874 lambda 0.6916\n",
      "epoch 397: train D loss: 0.6490, train F loss: -0.3935, acc 0.9836 lambda 0.6917\n",
      "epoch 398: train D loss: 0.6550, train F loss: -0.4034, acc 0.9872 lambda 0.6918\n",
      "epoch 399: train D loss: 0.6523, train F loss: -0.3982, acc 0.9858 lambda 0.6919\n",
      "epoch 400: train D loss: 0.6569, train F loss: -0.4016, acc 0.9864 lambda 0.6920\n",
      "epoch 401: train D loss: 0.6495, train F loss: -0.3958, acc 0.9852 lambda 0.6921\n",
      "epoch 402: train D loss: 0.6518, train F loss: -0.3958, acc 0.9866 lambda 0.6922\n",
      "epoch 403: train D loss: 0.6587, train F loss: -0.3888, acc 0.9832 lambda 0.6923\n",
      "epoch 404: train D loss: 0.6533, train F loss: -0.3883, acc 0.9854 lambda 0.6924\n",
      "epoch 405: train D loss: 0.6481, train F loss: -0.3923, acc 0.9840 lambda 0.6925\n",
      "epoch 406: train D loss: 0.6534, train F loss: -0.3926, acc 0.9848 lambda 0.6925\n",
      "epoch 407: train D loss: 0.6502, train F loss: -0.3971, acc 0.9860 lambda 0.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 408: train D loss: 0.6553, train F loss: -0.3891, acc 0.9838 lambda 0.6927\n",
      "epoch 409: train D loss: 0.6570, train F loss: -0.3949, acc 0.9812 lambda 0.6928\n",
      "epoch 410: train D loss: 0.6576, train F loss: -0.4057, acc 0.9852 lambda 0.6929\n",
      "epoch 411: train D loss: 0.6512, train F loss: -0.4103, acc 0.9884 lambda 0.6930\n",
      "epoch 412: train D loss: 0.6529, train F loss: -0.4022, acc 0.9864 lambda 0.6931\n",
      "epoch 413: train D loss: 0.6575, train F loss: -0.3883, acc 0.9820 lambda 0.6932\n",
      "epoch 414: train D loss: 0.6499, train F loss: -0.3895, acc 0.9824 lambda 0.6933\n",
      "epoch 415: train D loss: 0.6533, train F loss: -0.3959, acc 0.9862 lambda 0.6933\n",
      "epoch 416: train D loss: 0.6545, train F loss: -0.4002, acc 0.9848 lambda 0.6934\n",
      "epoch 417: train D loss: 0.6491, train F loss: -0.3993, acc 0.9864 lambda 0.6935\n",
      "epoch 418: train D loss: 0.6559, train F loss: -0.3979, acc 0.9824 lambda 0.6936\n",
      "epoch 419: train D loss: 0.6498, train F loss: -0.3936, acc 0.9832 lambda 0.6937\n",
      "epoch 420: train D loss: 0.6577, train F loss: -0.3931, acc 0.9844 lambda 0.6937\n",
      "epoch 421: train D loss: 0.6453, train F loss: -0.3905, acc 0.9848 lambda 0.6938\n",
      "epoch 422: train D loss: 0.6573, train F loss: -0.4049, acc 0.9854 lambda 0.6939\n",
      "epoch 423: train D loss: 0.6517, train F loss: -0.4012, acc 0.9858 lambda 0.6940\n",
      "epoch 424: train D loss: 0.6443, train F loss: -0.3996, acc 0.9876 lambda 0.6940\n",
      "epoch 425: train D loss: 0.6487, train F loss: -0.3960, acc 0.9860 lambda 0.6941\n",
      "epoch 426: train D loss: 0.6582, train F loss: -0.4015, acc 0.9840 lambda 0.6942\n",
      "epoch 427: train D loss: 0.6472, train F loss: -0.4009, acc 0.9854 lambda 0.6943\n",
      "epoch 428: train D loss: 0.6519, train F loss: -0.4067, acc 0.9890 lambda 0.6943\n",
      "epoch 429: train D loss: 0.6553, train F loss: -0.3971, acc 0.9860 lambda 0.6944\n",
      "epoch 430: train D loss: 0.6583, train F loss: -0.4052, acc 0.9864 lambda 0.6945\n",
      "epoch 431: train D loss: 0.6536, train F loss: -0.3984, acc 0.9838 lambda 0.6945\n",
      "epoch 432: train D loss: 0.6528, train F loss: -0.3993, acc 0.9844 lambda 0.6946\n",
      "epoch 433: train D loss: 0.6569, train F loss: -0.4105, acc 0.9884 lambda 0.6947\n",
      "epoch 434: train D loss: 0.6606, train F loss: -0.3979, acc 0.9820 lambda 0.6947\n",
      "epoch 435: train D loss: 0.6643, train F loss: -0.4115, acc 0.9848 lambda 0.6948\n",
      "epoch 436: train D loss: 0.6509, train F loss: -0.3966, acc 0.9836 lambda 0.6949\n",
      "epoch 437: train D loss: 0.6523, train F loss: -0.3962, acc 0.9840 lambda 0.6949\n",
      "epoch 438: train D loss: 0.6570, train F loss: -0.4033, acc 0.9872 lambda 0.6950\n",
      "epoch 439: train D loss: 0.6530, train F loss: -0.4055, acc 0.9872 lambda 0.6951\n",
      "epoch 440: train D loss: 0.6562, train F loss: -0.3995, acc 0.9834 lambda 0.6951\n",
      "epoch 441: train D loss: 0.6511, train F loss: -0.3944, acc 0.9860 lambda 0.6952\n",
      "epoch 442: train D loss: 0.6546, train F loss: -0.4036, acc 0.9864 lambda 0.6952\n",
      "epoch 443: train D loss: 0.6555, train F loss: -0.4023, acc 0.9858 lambda 0.6953\n",
      "epoch 444: train D loss: 0.6631, train F loss: -0.4008, acc 0.9842 lambda 0.6954\n",
      "epoch 445: train D loss: 0.6543, train F loss: -0.4105, acc 0.9872 lambda 0.6954\n",
      "epoch 446: train D loss: 0.6512, train F loss: -0.3875, acc 0.9830 lambda 0.6955\n",
      "epoch 447: train D loss: 0.6562, train F loss: -0.4123, acc 0.9886 lambda 0.6955\n",
      "epoch 448: train D loss: 0.6567, train F loss: -0.4104, acc 0.9888 lambda 0.6956\n",
      "epoch 449: train D loss: 0.6594, train F loss: -0.4086, acc 0.9830 lambda 0.6956\n",
      "epoch 450: train D loss: 0.6515, train F loss: -0.3925, acc 0.9852 lambda 0.6957\n",
      "epoch 451: train D loss: 0.6582, train F loss: -0.3980, acc 0.9838 lambda 0.6957\n",
      "epoch 452: train D loss: 0.6647, train F loss: -0.4019, acc 0.9846 lambda 0.6958\n",
      "epoch 453: train D loss: 0.6502, train F loss: -0.4015, acc 0.9860 lambda 0.6958\n",
      "epoch 454: train D loss: 0.6570, train F loss: -0.4062, acc 0.9842 lambda 0.6959\n",
      "epoch 455: train D loss: 0.6534, train F loss: -0.4007, acc 0.9842 lambda 0.6959\n",
      "epoch 456: train D loss: 0.6580, train F loss: -0.4181, acc 0.9890 lambda 0.6960\n",
      "epoch 457: train D loss: 0.6520, train F loss: -0.4094, acc 0.9880 lambda 0.6960\n",
      "epoch 458: train D loss: 0.6571, train F loss: -0.4014, acc 0.9840 lambda 0.6961\n",
      "epoch 459: train D loss: 0.6520, train F loss: -0.4106, acc 0.9896 lambda 0.6961\n",
      "epoch 460: train D loss: 0.6523, train F loss: -0.4072, acc 0.9876 lambda 0.6962\n",
      "epoch 461: train D loss: 0.6582, train F loss: -0.4008, acc 0.9870 lambda 0.6962\n",
      "epoch 462: train D loss: 0.6535, train F loss: -0.3958, acc 0.9820 lambda 0.6963\n",
      "epoch 463: train D loss: 0.6495, train F loss: -0.4022, acc 0.9866 lambda 0.6963\n",
      "epoch 464: train D loss: 0.6550, train F loss: -0.4089, acc 0.9864 lambda 0.6964\n",
      "epoch 465: train D loss: 0.6518, train F loss: -0.4014, acc 0.9846 lambda 0.6964\n",
      "epoch 466: train D loss: 0.6484, train F loss: -0.4001, acc 0.9874 lambda 0.6965\n",
      "epoch 467: train D loss: 0.6566, train F loss: -0.4076, acc 0.9876 lambda 0.6965\n",
      "epoch 468: train D loss: 0.6556, train F loss: -0.4102, acc 0.9860 lambda 0.6966\n",
      "epoch 469: train D loss: 0.6514, train F loss: -0.4079, acc 0.9876 lambda 0.6966\n",
      "epoch 470: train D loss: 0.6553, train F loss: -0.4038, acc 0.9848 lambda 0.6966\n",
      "epoch 471: train D loss: 0.6611, train F loss: -0.4075, acc 0.9840 lambda 0.6967\n",
      "epoch 472: train D loss: 0.6635, train F loss: -0.3968, acc 0.9862 lambda 0.6967\n",
      "epoch 473: train D loss: 0.6560, train F loss: -0.4039, acc 0.9844 lambda 0.6968\n",
      "epoch 474: train D loss: 0.6507, train F loss: -0.3943, acc 0.9848 lambda 0.6968\n",
      "epoch 475: train D loss: 0.6531, train F loss: -0.3921, acc 0.9858 lambda 0.6968\n",
      "epoch 476: train D loss: 0.6554, train F loss: -0.4127, acc 0.9872 lambda 0.6969\n",
      "epoch 477: train D loss: 0.6493, train F loss: -0.4069, acc 0.9884 lambda 0.6969\n",
      "epoch 478: train D loss: 0.6569, train F loss: -0.4110, acc 0.9858 lambda 0.6970\n",
      "epoch 479: train D loss: 0.6570, train F loss: -0.4138, acc 0.9882 lambda 0.6970\n",
      "epoch 480: train D loss: 0.6599, train F loss: -0.4072, acc 0.9858 lambda 0.6970\n",
      "epoch 481: train D loss: 0.6610, train F loss: -0.4113, acc 0.9864 lambda 0.6971\n",
      "epoch 482: train D loss: 0.6497, train F loss: -0.3989, acc 0.9864 lambda 0.6971\n",
      "epoch 483: train D loss: 0.6559, train F loss: -0.4091, acc 0.9854 lambda 0.6971\n",
      "epoch 484: train D loss: 0.6616, train F loss: -0.4099, acc 0.9844 lambda 0.6972\n",
      "epoch 485: train D loss: 0.6598, train F loss: -0.4060, acc 0.9852 lambda 0.6972\n",
      "epoch 486: train D loss: 0.6539, train F loss: -0.4019, acc 0.9848 lambda 0.6972\n",
      "epoch 487: train D loss: 0.6555, train F loss: -0.3944, acc 0.9844 lambda 0.6973\n",
      "epoch 488: train D loss: 0.6520, train F loss: -0.4040, acc 0.9880 lambda 0.6973\n",
      "epoch 489: train D loss: 0.6568, train F loss: -0.4035, acc 0.9858 lambda 0.6973\n",
      "epoch 490: train D loss: 0.6536, train F loss: -0.4063, acc 0.9856 lambda 0.6974\n",
      "epoch 491: train D loss: 0.6601, train F loss: -0.3899, acc 0.9814 lambda 0.6974\n",
      "epoch 492: train D loss: 0.6566, train F loss: -0.4078, acc 0.9852 lambda 0.6974\n",
      "epoch 493: train D loss: 0.6569, train F loss: -0.4106, acc 0.9892 lambda 0.6975\n",
      "epoch 494: train D loss: 0.6502, train F loss: -0.4017, acc 0.9870 lambda 0.6975\n",
      "epoch 495: train D loss: 0.6612, train F loss: -0.4142, acc 0.9866 lambda 0.6975\n",
      "epoch 496: train D loss: 0.6553, train F loss: -0.4111, acc 0.9892 lambda 0.6976\n",
      "epoch 497: train D loss: 0.6637, train F loss: -0.4024, acc 0.9826 lambda 0.6976\n",
      "epoch 498: train D loss: 0.6542, train F loss: -0.4120, acc 0.9880 lambda 0.6976\n",
      "epoch 499: train D loss: 0.6582, train F loss: -0.4152, acc 0.9886 lambda 0.6977\n",
      "epoch 500: train D loss: 0.6535, train F loss: -0.4094, acc 0.9896 lambda 0.6977\n",
      "epoch 501: train D loss: 0.6541, train F loss: -0.4102, acc 0.9882 lambda 0.6977\n",
      "epoch 502: train D loss: 0.6593, train F loss: -0.4158, acc 0.9894 lambda 0.6977\n",
      "epoch 503: train D loss: 0.6527, train F loss: -0.4097, acc 0.9876 lambda 0.6978\n",
      "epoch 504: train D loss: 0.6564, train F loss: -0.4155, acc 0.9892 lambda 0.6978\n",
      "epoch 505: train D loss: 0.6632, train F loss: -0.4115, acc 0.9856 lambda 0.6978\n",
      "epoch 506: train D loss: 0.6580, train F loss: -0.3934, acc 0.9844 lambda 0.6979\n",
      "epoch 507: train D loss: 0.6556, train F loss: -0.4074, acc 0.9856 lambda 0.6979\n",
      "epoch 508: train D loss: 0.6526, train F loss: -0.4046, acc 0.9866 lambda 0.6979\n",
      "epoch 509: train D loss: 0.6549, train F loss: -0.3992, acc 0.9818 lambda 0.6979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 510: train D loss: 0.6574, train F loss: -0.4131, acc 0.9870 lambda 0.6980\n",
      "epoch 511: train D loss: 0.6588, train F loss: -0.4091, acc 0.9872 lambda 0.6980\n",
      "epoch 512: train D loss: 0.6582, train F loss: -0.4189, acc 0.9886 lambda 0.6980\n",
      "epoch 513: train D loss: 0.6627, train F loss: -0.4162, acc 0.9870 lambda 0.6980\n",
      "epoch 514: train D loss: 0.6573, train F loss: -0.4007, acc 0.9842 lambda 0.6981\n",
      "epoch 515: train D loss: 0.6632, train F loss: -0.4265, acc 0.9886 lambda 0.6981\n",
      "epoch 516: train D loss: 0.6588, train F loss: -0.4024, acc 0.9856 lambda 0.6981\n",
      "epoch 517: train D loss: 0.6551, train F loss: -0.4160, acc 0.9878 lambda 0.6981\n",
      "epoch 518: train D loss: 0.6551, train F loss: -0.4069, acc 0.9878 lambda 0.6982\n",
      "epoch 519: train D loss: 0.6513, train F loss: -0.4121, acc 0.9884 lambda 0.6982\n",
      "epoch 520: train D loss: 0.6576, train F loss: -0.4080, acc 0.9860 lambda 0.6982\n",
      "epoch 521: train D loss: 0.6591, train F loss: -0.4079, acc 0.9846 lambda 0.6982\n",
      "epoch 522: train D loss: 0.6599, train F loss: -0.4064, acc 0.9840 lambda 0.6982\n",
      "epoch 523: train D loss: 0.6523, train F loss: -0.4007, acc 0.9846 lambda 0.6983\n",
      "epoch 524: train D loss: 0.6560, train F loss: -0.4020, acc 0.9870 lambda 0.6983\n",
      "epoch 525: train D loss: 0.6559, train F loss: -0.4034, acc 0.9848 lambda 0.6983\n",
      "epoch 526: train D loss: 0.6521, train F loss: -0.4055, acc 0.9862 lambda 0.6983\n",
      "epoch 527: train D loss: 0.6553, train F loss: -0.4108, acc 0.9886 lambda 0.6983\n",
      "epoch 528: train D loss: 0.6569, train F loss: -0.4119, acc 0.9868 lambda 0.6984\n",
      "epoch 529: train D loss: 0.6457, train F loss: -0.4080, acc 0.9888 lambda 0.6984\n",
      "epoch 530: train D loss: 0.6560, train F loss: -0.4084, acc 0.9870 lambda 0.6984\n",
      "epoch 531: train D loss: 0.6562, train F loss: -0.4094, acc 0.9876 lambda 0.6984\n",
      "epoch 532: train D loss: 0.6491, train F loss: -0.3930, acc 0.9844 lambda 0.6984\n",
      "epoch 533: train D loss: 0.6565, train F loss: -0.4105, acc 0.9882 lambda 0.6985\n",
      "epoch 534: train D loss: 0.6537, train F loss: -0.4172, acc 0.9880 lambda 0.6985\n",
      "epoch 535: train D loss: 0.6595, train F loss: -0.4043, acc 0.9852 lambda 0.6985\n",
      "epoch 536: train D loss: 0.6559, train F loss: -0.4020, acc 0.9846 lambda 0.6985\n",
      "epoch 537: train D loss: 0.6533, train F loss: -0.4159, acc 0.9898 lambda 0.6985\n",
      "epoch 538: train D loss: 0.6593, train F loss: -0.4154, acc 0.9880 lambda 0.6986\n",
      "epoch 539: train D loss: 0.6622, train F loss: -0.4199, acc 0.9892 lambda 0.6986\n",
      "epoch 540: train D loss: 0.6600, train F loss: -0.4125, acc 0.9856 lambda 0.6986\n",
      "epoch 541: train D loss: 0.6514, train F loss: -0.4100, acc 0.9890 lambda 0.6986\n",
      "epoch 542: train D loss: 0.6540, train F loss: -0.4021, acc 0.9878 lambda 0.6986\n",
      "epoch 543: train D loss: 0.6554, train F loss: -0.4003, acc 0.9854 lambda 0.6986\n",
      "epoch 544: train D loss: 0.6561, train F loss: -0.4129, acc 0.9880 lambda 0.6987\n",
      "epoch 545: train D loss: 0.6566, train F loss: -0.4169, acc 0.9884 lambda 0.6987\n",
      "epoch 546: train D loss: 0.6477, train F loss: -0.3592, acc 0.9794 lambda 0.6987\n",
      "epoch 547: train D loss: 0.6564, train F loss: -0.4160, acc 0.9902 lambda 0.6987\n",
      "epoch 548: train D loss: 0.6544, train F loss: -0.4104, acc 0.9886 lambda 0.6987\n",
      "epoch 549: train D loss: 0.6567, train F loss: -0.4044, acc 0.9878 lambda 0.6987\n",
      "epoch 550: train D loss: 0.6482, train F loss: -0.4043, acc 0.9882 lambda 0.6988\n",
      "epoch 551: train D loss: 0.6563, train F loss: -0.4190, acc 0.9894 lambda 0.6988\n",
      "epoch 552: train D loss: 0.6559, train F loss: -0.4158, acc 0.9884 lambda 0.6988\n",
      "epoch 553: train D loss: 0.6578, train F loss: -0.4208, acc 0.9894 lambda 0.6988\n",
      "epoch 554: train D loss: 0.6573, train F loss: -0.4140, acc 0.9892 lambda 0.6988\n",
      "epoch 555: train D loss: 0.6556, train F loss: -0.4153, acc 0.9884 lambda 0.6988\n",
      "epoch 556: train D loss: 0.6596, train F loss: -0.4162, acc 0.9886 lambda 0.6989\n",
      "epoch 557: train D loss: 0.6547, train F loss: -0.4061, acc 0.9864 lambda 0.6989\n",
      "epoch 558: train D loss: 0.6562, train F loss: -0.4132, acc 0.9876 lambda 0.6989\n",
      "epoch 559: train D loss: 0.6532, train F loss: -0.4088, acc 0.9876 lambda 0.6989\n",
      "epoch 560: train D loss: 0.6527, train F loss: -0.3717, acc 0.9844 lambda 0.6989\n",
      "epoch 561: train D loss: 0.6579, train F loss: -0.4127, acc 0.9882 lambda 0.6989\n",
      "epoch 562: train D loss: 0.6565, train F loss: -0.4143, acc 0.9876 lambda 0.6989\n",
      "epoch 563: train D loss: 0.6576, train F loss: -0.4189, acc 0.9888 lambda 0.6989\n",
      "epoch 564: train D loss: 0.6546, train F loss: -0.4007, acc 0.9850 lambda 0.6990\n",
      "epoch 565: train D loss: 0.6511, train F loss: -0.4104, acc 0.9884 lambda 0.6990\n",
      "epoch 566: train D loss: 0.6521, train F loss: -0.4099, acc 0.9870 lambda 0.6990\n",
      "epoch 567: train D loss: 0.6571, train F loss: -0.4191, acc 0.9882 lambda 0.6990\n",
      "epoch 568: train D loss: 0.6535, train F loss: -0.4049, acc 0.9864 lambda 0.6990\n",
      "epoch 569: train D loss: 0.6550, train F loss: -0.4178, acc 0.9908 lambda 0.6990\n",
      "epoch 570: train D loss: 0.6584, train F loss: -0.4087, acc 0.9864 lambda 0.6990\n",
      "epoch 571: train D loss: 0.6649, train F loss: -0.4212, acc 0.9886 lambda 0.6990\n",
      "epoch 572: train D loss: 0.6485, train F loss: -0.4086, acc 0.9890 lambda 0.6991\n",
      "epoch 573: train D loss: 0.6584, train F loss: -0.4093, acc 0.9854 lambda 0.6991\n",
      "epoch 574: train D loss: 0.6588, train F loss: -0.4040, acc 0.9850 lambda 0.6991\n",
      "epoch 575: train D loss: 0.6580, train F loss: -0.4144, acc 0.9874 lambda 0.6991\n",
      "epoch 576: train D loss: 0.6559, train F loss: -0.4135, acc 0.9872 lambda 0.6991\n",
      "epoch 577: train D loss: 0.6517, train F loss: -0.3996, acc 0.9872 lambda 0.6991\n",
      "epoch 578: train D loss: 0.6604, train F loss: -0.4259, acc 0.9912 lambda 0.6991\n",
      "epoch 579: train D loss: 0.6558, train F loss: -0.4137, acc 0.9890 lambda 0.6991\n",
      "epoch 580: train D loss: 0.6593, train F loss: -0.4094, acc 0.9836 lambda 0.6991\n",
      "epoch 581: train D loss: 0.6590, train F loss: -0.4128, acc 0.9870 lambda 0.6992\n",
      "epoch 582: train D loss: 0.6551, train F loss: -0.4126, acc 0.9884 lambda 0.6992\n",
      "epoch 583: train D loss: 0.6567, train F loss: -0.4125, acc 0.9870 lambda 0.6992\n",
      "epoch 584: train D loss: 0.6581, train F loss: -0.4205, acc 0.9876 lambda 0.6992\n",
      "epoch 585: train D loss: 0.6579, train F loss: -0.4112, acc 0.9874 lambda 0.6992\n",
      "epoch 586: train D loss: 0.6502, train F loss: -0.4104, acc 0.9882 lambda 0.6992\n",
      "epoch 587: train D loss: 0.6596, train F loss: -0.4042, acc 0.9850 lambda 0.6992\n",
      "epoch 588: train D loss: 0.6569, train F loss: -0.4131, acc 0.9876 lambda 0.6992\n",
      "epoch 589: train D loss: 0.6505, train F loss: -0.4129, acc 0.9900 lambda 0.6992\n",
      "epoch 590: train D loss: 0.6483, train F loss: -0.4075, acc 0.9870 lambda 0.6992\n",
      "epoch 591: train D loss: 0.6530, train F loss: -0.3998, acc 0.9870 lambda 0.6993\n",
      "epoch 592: train D loss: 0.6556, train F loss: -0.4160, acc 0.9900 lambda 0.6993\n",
      "epoch 593: train D loss: 0.6551, train F loss: -0.4170, acc 0.9886 lambda 0.6993\n",
      "epoch 594: train D loss: 0.6611, train F loss: -0.4217, acc 0.9880 lambda 0.6993\n",
      "epoch 595: train D loss: 0.6560, train F loss: -0.4152, acc 0.9896 lambda 0.6993\n",
      "epoch 596: train D loss: 0.6595, train F loss: -0.4152, acc 0.9876 lambda 0.6993\n",
      "epoch 597: train D loss: 0.6593, train F loss: -0.4067, acc 0.9860 lambda 0.6993\n",
      "epoch 598: train D loss: 0.6607, train F loss: -0.4115, acc 0.9854 lambda 0.6993\n",
      "epoch 599: train D loss: 0.6592, train F loss: -0.4217, acc 0.9890 lambda 0.6993\n",
      "epoch 600: train D loss: 0.6574, train F loss: -0.4045, acc 0.9848 lambda 0.6993\n",
      "epoch 601: train D loss: 0.6577, train F loss: -0.4196, acc 0.9878 lambda 0.6993\n",
      "epoch 602: train D loss: 0.6598, train F loss: -0.4141, acc 0.9870 lambda 0.6994\n",
      "epoch 603: train D loss: 0.6583, train F loss: -0.4206, acc 0.9886 lambda 0.6994\n",
      "epoch 604: train D loss: 0.6571, train F loss: -0.4262, acc 0.9930 lambda 0.6994\n",
      "epoch 605: train D loss: 0.6559, train F loss: -0.4091, acc 0.9882 lambda 0.6994\n",
      "epoch 606: train D loss: 0.6610, train F loss: -0.4157, acc 0.9874 lambda 0.6994\n",
      "epoch 607: train D loss: 0.6622, train F loss: -0.4168, acc 0.9870 lambda 0.6994\n",
      "epoch 608: train D loss: 0.6599, train F loss: -0.4215, acc 0.9890 lambda 0.6994\n",
      "epoch 609: train D loss: 0.6572, train F loss: -0.4132, acc 0.9874 lambda 0.6994\n",
      "epoch 610: train D loss: 0.6517, train F loss: -0.4101, acc 0.9878 lambda 0.6994\n",
      "epoch 611: train D loss: 0.6603, train F loss: -0.4238, acc 0.9906 lambda 0.6994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 612: train D loss: 0.6554, train F loss: -0.4154, acc 0.9906 lambda 0.6994\n",
      "epoch 613: train D loss: 0.6553, train F loss: -0.4113, acc 0.9870 lambda 0.6994\n",
      "epoch 614: train D loss: 0.6584, train F loss: -0.4235, acc 0.9908 lambda 0.6994\n",
      "epoch 615: train D loss: 0.6564, train F loss: -0.4169, acc 0.9876 lambda 0.6995\n",
      "epoch 616: train D loss: 0.6529, train F loss: -0.4105, acc 0.9882 lambda 0.6995\n",
      "epoch 617: train D loss: 0.6614, train F loss: -0.4260, acc 0.9910 lambda 0.6995\n",
      "epoch 618: train D loss: 0.6576, train F loss: -0.4105, acc 0.9860 lambda 0.6995\n",
      "epoch 619: train D loss: 0.6565, train F loss: -0.4216, acc 0.9902 lambda 0.6995\n",
      "epoch 620: train D loss: 0.6579, train F loss: -0.4128, acc 0.9860 lambda 0.6995\n",
      "epoch 621: train D loss: 0.6623, train F loss: -0.4089, acc 0.9854 lambda 0.6995\n",
      "epoch 622: train D loss: 0.6552, train F loss: -0.4140, acc 0.9886 lambda 0.6995\n",
      "epoch 623: train D loss: 0.6553, train F loss: -0.4048, acc 0.9858 lambda 0.6995\n",
      "epoch 624: train D loss: 0.6652, train F loss: -0.4179, acc 0.9862 lambda 0.6995\n",
      "epoch 625: train D loss: 0.6584, train F loss: -0.4130, acc 0.9876 lambda 0.6995\n",
      "epoch 626: train D loss: 0.6600, train F loss: -0.4150, acc 0.9850 lambda 0.6995\n",
      "epoch 627: train D loss: 0.6628, train F loss: -0.4178, acc 0.9860 lambda 0.6995\n",
      "epoch 628: train D loss: 0.6606, train F loss: -0.4135, acc 0.9854 lambda 0.6995\n",
      "epoch 629: train D loss: 0.6560, train F loss: -0.4117, acc 0.9880 lambda 0.6995\n",
      "epoch 630: train D loss: 0.6546, train F loss: -0.4175, acc 0.9888 lambda 0.6995\n",
      "epoch 631: train D loss: 0.6536, train F loss: -0.4114, acc 0.9880 lambda 0.6995\n",
      "epoch 632: train D loss: 0.6563, train F loss: -0.4172, acc 0.9880 lambda 0.6996\n",
      "epoch 633: train D loss: 0.6589, train F loss: -0.4165, acc 0.9890 lambda 0.6996\n",
      "epoch 634: train D loss: 0.6583, train F loss: -0.4178, acc 0.9892 lambda 0.6996\n",
      "epoch 635: train D loss: 0.6551, train F loss: -0.4108, acc 0.9880 lambda 0.6996\n",
      "epoch 636: train D loss: 0.6600, train F loss: -0.4171, acc 0.9880 lambda 0.6996\n",
      "epoch 637: train D loss: 0.6597, train F loss: -0.4175, acc 0.9890 lambda 0.6996\n",
      "epoch 638: train D loss: 0.6534, train F loss: -0.4082, acc 0.9870 lambda 0.6996\n",
      "epoch 639: train D loss: 0.6595, train F loss: -0.4194, acc 0.9892 lambda 0.6996\n",
      "epoch 640: train D loss: 0.6563, train F loss: -0.4084, acc 0.9854 lambda 0.6996\n",
      "epoch 641: train D loss: 0.6572, train F loss: -0.4145, acc 0.9894 lambda 0.6996\n",
      "epoch 642: train D loss: 0.6583, train F loss: -0.4233, acc 0.9906 lambda 0.6996\n",
      "epoch 643: train D loss: 0.6617, train F loss: -0.4096, acc 0.9870 lambda 0.6996\n",
      "epoch 644: train D loss: 0.6580, train F loss: -0.4151, acc 0.9880 lambda 0.6996\n",
      "epoch 645: train D loss: 0.6601, train F loss: -0.4100, acc 0.9858 lambda 0.6996\n",
      "epoch 646: train D loss: 0.6582, train F loss: -0.4235, acc 0.9894 lambda 0.6996\n",
      "epoch 647: train D loss: 0.6560, train F loss: -0.4197, acc 0.9892 lambda 0.6996\n",
      "epoch 648: train D loss: 0.6571, train F loss: -0.4174, acc 0.9894 lambda 0.6996\n",
      "epoch 649: train D loss: 0.6560, train F loss: -0.4095, acc 0.9864 lambda 0.6996\n",
      "epoch 650: train D loss: 0.6573, train F loss: -0.4229, acc 0.9906 lambda 0.6996\n",
      "epoch 651: train D loss: 0.6604, train F loss: -0.4219, acc 0.9878 lambda 0.6996\n",
      "epoch 652: train D loss: 0.6565, train F loss: -0.4052, acc 0.9856 lambda 0.6997\n",
      "epoch 653: train D loss: 0.6553, train F loss: -0.4155, acc 0.9888 lambda 0.6997\n",
      "epoch 654: train D loss: 0.6601, train F loss: -0.4255, acc 0.9904 lambda 0.6997\n",
      "epoch 655: train D loss: 0.6553, train F loss: -0.4207, acc 0.9902 lambda 0.6997\n",
      "epoch 656: train D loss: 0.6621, train F loss: -0.4192, acc 0.9870 lambda 0.6997\n",
      "epoch 657: train D loss: 0.6540, train F loss: -0.4209, acc 0.9910 lambda 0.6997\n",
      "epoch 658: train D loss: 0.6596, train F loss: -0.4188, acc 0.9888 lambda 0.6997\n",
      "epoch 659: train D loss: 0.6603, train F loss: -0.4217, acc 0.9888 lambda 0.6997\n",
      "epoch 660: train D loss: 0.6566, train F loss: -0.4260, acc 0.9906 lambda 0.6997\n",
      "epoch 661: train D loss: 0.6607, train F loss: -0.4155, acc 0.9874 lambda 0.6997\n",
      "epoch 662: train D loss: 0.6544, train F loss: -0.4049, acc 0.9858 lambda 0.6997\n",
      "epoch 663: train D loss: 0.6541, train F loss: -0.4181, acc 0.9908 lambda 0.6997\n",
      "epoch 664: train D loss: 0.6599, train F loss: -0.4194, acc 0.9892 lambda 0.6997\n",
      "epoch 665: train D loss: 0.6704, train F loss: -0.4301, acc 0.9892 lambda 0.6997\n",
      "epoch 666: train D loss: 0.6590, train F loss: -0.4170, acc 0.9874 lambda 0.6997\n",
      "epoch 667: train D loss: 0.6590, train F loss: -0.4171, acc 0.9888 lambda 0.6997\n",
      "epoch 668: train D loss: 0.6559, train F loss: -0.3938, acc 0.9860 lambda 0.6997\n",
      "epoch 669: train D loss: 0.6537, train F loss: -0.4021, acc 0.9862 lambda 0.6997\n",
      "epoch 670: train D loss: 0.6571, train F loss: -0.4243, acc 0.9920 lambda 0.6997\n",
      "epoch 671: train D loss: 0.6551, train F loss: -0.4193, acc 0.9904 lambda 0.6997\n",
      "epoch 672: train D loss: 0.6608, train F loss: -0.4261, acc 0.9910 lambda 0.6997\n",
      "epoch 673: train D loss: 0.6623, train F loss: -0.4167, acc 0.9878 lambda 0.6997\n",
      "epoch 674: train D loss: 0.6652, train F loss: -0.4199, acc 0.9888 lambda 0.6997\n",
      "epoch 675: train D loss: 0.6614, train F loss: -0.4205, acc 0.9890 lambda 0.6997\n",
      "epoch 676: train D loss: 0.6590, train F loss: -0.4225, acc 0.9884 lambda 0.6997\n",
      "epoch 677: train D loss: 0.6577, train F loss: -0.4187, acc 0.9896 lambda 0.6997\n",
      "epoch 678: train D loss: 0.6561, train F loss: -0.4180, acc 0.9890 lambda 0.6997\n",
      "epoch 679: train D loss: 0.6561, train F loss: -0.4189, acc 0.9888 lambda 0.6998\n",
      "epoch 680: train D loss: 0.6599, train F loss: -0.4232, acc 0.9898 lambda 0.6998\n",
      "epoch 681: train D loss: 0.6601, train F loss: -0.4237, acc 0.9890 lambda 0.6998\n",
      "epoch 682: train D loss: 0.6618, train F loss: -0.4154, acc 0.9854 lambda 0.6998\n",
      "epoch 683: train D loss: 0.6538, train F loss: -0.4062, acc 0.9864 lambda 0.6998\n",
      "epoch 684: train D loss: 0.6496, train F loss: -0.4179, acc 0.9888 lambda 0.6998\n",
      "epoch 685: train D loss: 0.6553, train F loss: -0.4072, acc 0.9862 lambda 0.6998\n",
      "epoch 686: train D loss: 0.6551, train F loss: -0.4135, acc 0.9904 lambda 0.6998\n",
      "epoch 687: train D loss: 0.6580, train F loss: -0.4218, acc 0.9898 lambda 0.6998\n",
      "epoch 688: train D loss: 0.6656, train F loss: -0.4266, acc 0.9904 lambda 0.6998\n",
      "epoch 689: train D loss: 0.6610, train F loss: -0.4092, acc 0.9868 lambda 0.6998\n",
      "epoch 690: train D loss: 0.6516, train F loss: -0.4139, acc 0.9892 lambda 0.6998\n",
      "epoch 691: train D loss: 0.6570, train F loss: -0.4211, acc 0.9904 lambda 0.6998\n",
      "epoch 692: train D loss: 0.6625, train F loss: -0.4191, acc 0.9878 lambda 0.6998\n",
      "epoch 693: train D loss: 0.6598, train F loss: -0.4217, acc 0.9876 lambda 0.6998\n",
      "epoch 694: train D loss: 0.6585, train F loss: -0.4185, acc 0.9894 lambda 0.6998\n",
      "epoch 695: train D loss: 0.6576, train F loss: -0.4237, acc 0.9904 lambda 0.6998\n",
      "epoch 696: train D loss: 0.6603, train F loss: -0.4252, acc 0.9900 lambda 0.6998\n",
      "epoch 697: train D loss: 0.6540, train F loss: -0.4092, acc 0.9868 lambda 0.6998\n",
      "epoch 698: train D loss: 0.6561, train F loss: -0.4196, acc 0.9906 lambda 0.6998\n",
      "epoch 699: train D loss: 0.6681, train F loss: -0.4332, acc 0.9904 lambda 0.6998\n",
      "epoch 700: train D loss: 0.6602, train F loss: -0.4088, acc 0.9868 lambda 0.6998\n",
      "epoch 701: train D loss: 0.6614, train F loss: -0.4246, acc 0.9900 lambda 0.6998\n",
      "epoch 702: train D loss: 0.6607, train F loss: -0.4267, acc 0.9890 lambda 0.6998\n",
      "epoch 703: train D loss: 0.6592, train F loss: -0.4203, acc 0.9898 lambda 0.6998\n",
      "epoch 704: train D loss: 0.6591, train F loss: -0.4225, acc 0.9904 lambda 0.6998\n",
      "epoch 705: train D loss: 0.6683, train F loss: -0.4325, acc 0.9900 lambda 0.6998\n",
      "epoch 706: train D loss: 0.6595, train F loss: -0.4185, acc 0.9882 lambda 0.6998\n",
      "epoch 707: train D loss: 0.6622, train F loss: -0.4162, acc 0.9870 lambda 0.6998\n",
      "epoch 708: train D loss: 0.6572, train F loss: -0.4229, acc 0.9904 lambda 0.6998\n",
      "epoch 709: train D loss: 0.6574, train F loss: -0.4101, acc 0.9868 lambda 0.6998\n",
      "epoch 710: train D loss: 0.6577, train F loss: -0.4205, acc 0.9904 lambda 0.6998\n",
      "epoch 711: train D loss: 0.6605, train F loss: -0.4253, acc 0.9902 lambda 0.6998\n",
      "epoch 712: train D loss: 0.6622, train F loss: -0.4280, acc 0.9916 lambda 0.6998\n",
      "epoch 713: train D loss: 0.6700, train F loss: -0.4091, acc 0.9858 lambda 0.6998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 714: train D loss: 0.6616, train F loss: -0.4133, acc 0.9856 lambda 0.6998\n",
      "epoch 715: train D loss: 0.6538, train F loss: -0.3495, acc 0.9788 lambda 0.6998\n",
      "epoch 716: train D loss: 0.6544, train F loss: -0.4034, acc 0.9832 lambda 0.6998\n",
      "epoch 717: train D loss: 0.6552, train F loss: -0.4146, acc 0.9894 lambda 0.6998\n",
      "epoch 718: train D loss: 0.6502, train F loss: -0.4111, acc 0.9880 lambda 0.6998\n",
      "epoch 719: train D loss: 0.6504, train F loss: -0.4055, acc 0.9878 lambda 0.6999\n",
      "epoch 720: train D loss: 0.6571, train F loss: -0.4140, acc 0.9888 lambda 0.6999\n",
      "epoch 721: train D loss: 0.6574, train F loss: -0.4126, acc 0.9886 lambda 0.6999\n",
      "epoch 722: train D loss: 0.6532, train F loss: -0.4165, acc 0.9902 lambda 0.6999\n",
      "epoch 723: train D loss: 0.6547, train F loss: -0.4171, acc 0.9896 lambda 0.6999\n",
      "epoch 724: train D loss: 0.6589, train F loss: -0.4197, acc 0.9886 lambda 0.6999\n",
      "epoch 725: train D loss: 0.6562, train F loss: -0.4170, acc 0.9890 lambda 0.6999\n",
      "epoch 726: train D loss: 0.6558, train F loss: -0.4104, acc 0.9876 lambda 0.6999\n",
      "epoch 727: train D loss: 0.6637, train F loss: -0.4215, acc 0.9902 lambda 0.6999\n",
      "epoch 728: train D loss: 0.6568, train F loss: -0.4189, acc 0.9886 lambda 0.6999\n",
      "epoch 729: train D loss: 0.6626, train F loss: -0.4229, acc 0.9892 lambda 0.6999\n",
      "epoch 730: train D loss: 0.6593, train F loss: -0.4205, acc 0.9900 lambda 0.6999\n",
      "epoch 731: train D loss: 0.6536, train F loss: -0.4108, acc 0.9878 lambda 0.6999\n",
      "epoch 732: train D loss: 0.6602, train F loss: -0.4269, acc 0.9910 lambda 0.6999\n",
      "epoch 733: train D loss: 0.6552, train F loss: -0.4170, acc 0.9894 lambda 0.6999\n",
      "epoch 734: train D loss: 0.6597, train F loss: -0.4167, acc 0.9882 lambda 0.6999\n",
      "epoch 735: train D loss: 0.6600, train F loss: -0.4174, acc 0.9878 lambda 0.6999\n",
      "epoch 736: train D loss: 0.6618, train F loss: -0.4338, acc 0.9926 lambda 0.6999\n",
      "epoch 737: train D loss: 0.6589, train F loss: -0.4189, acc 0.9890 lambda 0.6999\n",
      "epoch 738: train D loss: 0.6521, train F loss: -0.4184, acc 0.9898 lambda 0.6999\n",
      "epoch 739: train D loss: 0.6607, train F loss: -0.4190, acc 0.9900 lambda 0.6999\n",
      "epoch 740: train D loss: 0.6567, train F loss: -0.4164, acc 0.9890 lambda 0.6999\n",
      "epoch 741: train D loss: 0.6603, train F loss: -0.4152, acc 0.9876 lambda 0.6999\n",
      "epoch 742: train D loss: 0.6678, train F loss: -0.4306, acc 0.9902 lambda 0.6999\n",
      "epoch 743: train D loss: 0.6562, train F loss: -0.4187, acc 0.9894 lambda 0.6999\n",
      "epoch 744: train D loss: 0.6575, train F loss: -0.4225, acc 0.9896 lambda 0.6999\n",
      "epoch 745: train D loss: 0.6561, train F loss: -0.4162, acc 0.9904 lambda 0.6999\n",
      "epoch 746: train D loss: 0.6599, train F loss: -0.3884, acc 0.9804 lambda 0.6999\n",
      "epoch 747: train D loss: 0.6546, train F loss: -0.4123, acc 0.9878 lambda 0.6999\n",
      "epoch 748: train D loss: 0.6584, train F loss: -0.4161, acc 0.9880 lambda 0.6999\n",
      "epoch 749: train D loss: 0.6571, train F loss: -0.4137, acc 0.9860 lambda 0.6999\n",
      "epoch 750: train D loss: 0.6587, train F loss: -0.4137, acc 0.9876 lambda 0.6999\n",
      "epoch 751: train D loss: 0.6642, train F loss: -0.4264, acc 0.9890 lambda 0.6999\n",
      "epoch 752: train D loss: 0.6585, train F loss: -0.4154, acc 0.9892 lambda 0.6999\n",
      "epoch 753: train D loss: 0.6558, train F loss: -0.4123, acc 0.9886 lambda 0.6999\n",
      "epoch 754: train D loss: 0.6486, train F loss: -0.4236, acc 0.9930 lambda 0.6999\n",
      "epoch 755: train D loss: 0.6584, train F loss: -0.4194, acc 0.9892 lambda 0.6999\n",
      "epoch 756: train D loss: 0.6602, train F loss: -0.4172, acc 0.9890 lambda 0.6999\n",
      "epoch 757: train D loss: 0.6577, train F loss: -0.4179, acc 0.9874 lambda 0.6999\n",
      "epoch 758: train D loss: 0.6606, train F loss: -0.4278, acc 0.9908 lambda 0.6999\n",
      "epoch 759: train D loss: 0.6573, train F loss: -0.4215, acc 0.9896 lambda 0.6999\n",
      "epoch 760: train D loss: 0.6601, train F loss: -0.4185, acc 0.9890 lambda 0.6999\n",
      "epoch 761: train D loss: 0.6643, train F loss: -0.4243, acc 0.9896 lambda 0.6999\n",
      "epoch 762: train D loss: 0.6626, train F loss: -0.4135, acc 0.9858 lambda 0.6999\n",
      "epoch 763: train D loss: 0.6575, train F loss: -0.4260, acc 0.9898 lambda 0.6999\n",
      "epoch 764: train D loss: 0.6646, train F loss: -0.4291, acc 0.9900 lambda 0.6999\n",
      "epoch 765: train D loss: 0.6531, train F loss: -0.4101, acc 0.9884 lambda 0.6999\n",
      "epoch 766: train D loss: 0.6654, train F loss: -0.4240, acc 0.9896 lambda 0.6999\n",
      "epoch 767: train D loss: 0.6543, train F loss: -0.4246, acc 0.9912 lambda 0.6999\n",
      "epoch 768: train D loss: 0.6627, train F loss: -0.4129, acc 0.9872 lambda 0.6999\n",
      "epoch 769: train D loss: 0.6554, train F loss: -0.4125, acc 0.9872 lambda 0.6999\n",
      "epoch 770: train D loss: 0.6630, train F loss: -0.4198, acc 0.9878 lambda 0.6999\n",
      "epoch 771: train D loss: 0.6578, train F loss: -0.4294, acc 0.9928 lambda 0.6999\n",
      "epoch 772: train D loss: 0.6569, train F loss: -0.4175, acc 0.9882 lambda 0.6999\n",
      "epoch 773: train D loss: 0.6600, train F loss: -0.4143, acc 0.9886 lambda 0.6999\n",
      "epoch 774: train D loss: 0.6611, train F loss: -0.4261, acc 0.9908 lambda 0.6999\n",
      "epoch 775: train D loss: 0.6578, train F loss: -0.4177, acc 0.9884 lambda 0.6999\n",
      "epoch 776: train D loss: 0.6549, train F loss: -0.4205, acc 0.9904 lambda 0.6999\n",
      "epoch 777: train D loss: 0.6567, train F loss: -0.4271, acc 0.9922 lambda 0.6999\n",
      "epoch 778: train D loss: 0.6576, train F loss: -0.4260, acc 0.9914 lambda 0.6999\n",
      "epoch 779: train D loss: 0.6588, train F loss: -0.4125, acc 0.9876 lambda 0.6999\n",
      "epoch 780: train D loss: 0.6575, train F loss: -0.4227, acc 0.9900 lambda 0.6999\n",
      "epoch 781: train D loss: 0.6620, train F loss: -0.4128, acc 0.9866 lambda 0.6999\n",
      "epoch 782: train D loss: 0.6610, train F loss: -0.4296, acc 0.9900 lambda 0.6999\n",
      "epoch 783: train D loss: 0.6552, train F loss: -0.4234, acc 0.9920 lambda 0.6999\n",
      "epoch 784: train D loss: 0.6675, train F loss: -0.4280, acc 0.9912 lambda 0.6999\n",
      "epoch 785: train D loss: 0.6618, train F loss: -0.4224, acc 0.9872 lambda 0.6999\n",
      "epoch 786: train D loss: 0.6558, train F loss: -0.4199, acc 0.9896 lambda 0.6999\n",
      "epoch 787: train D loss: 0.6587, train F loss: -0.4204, acc 0.9888 lambda 0.6999\n",
      "epoch 788: train D loss: 0.6584, train F loss: -0.4190, acc 0.9880 lambda 0.6999\n",
      "epoch 789: train D loss: 0.6553, train F loss: -0.4162, acc 0.9874 lambda 0.6999\n",
      "epoch 790: train D loss: 0.6635, train F loss: -0.4247, acc 0.9890 lambda 0.6999\n",
      "epoch 791: train D loss: 0.6596, train F loss: -0.4269, acc 0.9908 lambda 0.6999\n",
      "epoch 792: train D loss: 0.6618, train F loss: -0.4240, acc 0.9896 lambda 0.6999\n",
      "epoch 793: train D loss: 0.6621, train F loss: -0.4288, acc 0.9900 lambda 0.6999\n",
      "epoch 794: train D loss: 0.6584, train F loss: -0.4178, acc 0.9890 lambda 0.6999\n",
      "epoch 795: train D loss: 0.6570, train F loss: -0.4194, acc 0.9888 lambda 0.6999\n",
      "epoch 796: train D loss: 0.6584, train F loss: -0.4199, acc 0.9892 lambda 0.6999\n",
      "epoch 797: train D loss: 0.6607, train F loss: -0.4134, acc 0.9882 lambda 0.6999\n",
      "epoch 798: train D loss: 0.6620, train F loss: -0.4165, acc 0.9876 lambda 0.6999\n",
      "epoch 799: train D loss: 0.6585, train F loss: -0.4251, acc 0.9904 lambda 0.6999\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(source_dataloader, target_dataloader, lamb):\n",
    "    '''\n",
    "      Args:\n",
    "        source_dataloader: source data的dataloader\n",
    "        target_dataloader: target data的dataloader\n",
    "        lamb: control the balance of domain adaptatoin and classification.\n",
    "    '''\n",
    "\n",
    "    # D loss: Domain Classifier的loss\n",
    "    # F loss: Feature Extrator & Label Predictor的loss\n",
    "    running_D_loss, running_F_loss = 0.0, 0.0\n",
    "    total_hit, total_num = 0.0, 0.0\n",
    "\n",
    "    for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n",
    "\n",
    "        source_data = source_data.cuda()\n",
    "        source_label = source_label.cuda()\n",
    "        target_data = target_data.cuda()\n",
    "        \n",
    "        # Mixed the source data and target data, or it'll mislead the running params\n",
    "        #   of batch_norm. (runnning mean/var of soucre and target data are different.)\n",
    "        mixed_data = torch.cat([source_data, target_data], dim=0)\n",
    "        domain_label = torch.zeros([source_data.shape[0] + target_data.shape[0], 1]).cuda()\n",
    "        # set domain label of source data to be 1.\n",
    "        domain_label[:source_data.shape[0]] = 1\n",
    "\n",
    "        # Step 1 : train domain classifier\n",
    "        feature = feature_extractor(mixed_data)\n",
    "        # We don't need to train feature extractor in step 1.\n",
    "        # *Thus we detach the feature neuron to avoid backpropgation.\n",
    "        domain_logits = domain_classifier(feature.detach())\n",
    "        loss = domain_criterion(domain_logits, domain_label)\n",
    "        running_D_loss+= loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Step 2 : train feature extractor and label classifier\n",
    "        class_logits = label_predictor(feature[:source_data.shape[0]])\n",
    "        domain_logits = domain_classifier(feature)\n",
    "        # loss = cross entropy of classification - lamb * domain binary cross entropy.\n",
    "        #  The reason why using subtraction is similar to generator loss in disciminator of GAN\n",
    "        loss = class_criterion(class_logits, source_label) - lamb * domain_criterion(domain_logits, domain_label)\n",
    "        running_F_loss+= loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_F.step()\n",
    "        optimizer_C.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        optimizer_F.zero_grad()\n",
    "        optimizer_C.zero_grad()\n",
    "\n",
    "        total_hit += torch.sum(torch.argmax(class_logits, dim=1) == source_label).item()\n",
    "        total_num += source_data.shape[0]\n",
    "        print(i, end='\\r')\n",
    "\n",
    "    return running_D_loss / (i+1), running_F_loss / (i+1), total_hit / total_num\n",
    "\n",
    "# train 200 epochs\n",
    "for epoch in range(800):\n",
    "    #lambda gradually change from 0.1 to 0.7\n",
    "    t_lamb=1.2/(1+np.exp(-10*epoch/800))-0.5\n",
    "    \n",
    "    train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader, lamb=t_lamb)\n",
    "\n",
    "    torch.save(feature_extractor.state_dict(), f'extractor_model.bin')\n",
    "    torch.save(label_predictor.state_dict(), f'predictor_model.bin')\n",
    "\n",
    "    print('epoch {:>3d}: train D loss: {:6.4f}, train F loss: {:6.4f}, acc {:6.4f} lambda {:6.4f}'.format(epoch, train_D_loss, train_F_loss, train_acc,t_lamb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8_-0iSSje4w"
   },
   "source": [
    "# Inference\n",
    "\n",
    "We use pandas to generate our csv file.\n",
    "\n",
    "BTW, the performance of the model trained for 200 epoches might be unstable. You can train for more epoches for a more stable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Wly5AgH2jePv"
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "label_predictor.eval()\n",
    "feature_extractor.eval()\n",
    "for i, (test_data, _) in enumerate(test_dataloader):\n",
    "    test_data = test_data.cuda()\n",
    "\n",
    "    class_logits = label_predictor(feature_extractor(test_data))\n",
    "\n",
    "    x = torch.argmax(class_logits, dim=1).cpu().detach().numpy()\n",
    "    result.append(x)\n",
    "\n",
    "import pandas as pd\n",
    "result = np.concatenate(result)\n",
    "\n",
    "# Generate your submission\n",
    "df = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\n",
    "df.to_csv('DaNN_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpheoH_rvFbO"
   },
   "source": [
    "# Training Statistics\n",
    "\n",
    "- Number of parameters:\n",
    "  - Feature Extractor: 2, 142, 336\n",
    "  - Label Predictor: 530, 442\n",
    "  - Domain Classifier: 1, 055, 233\n",
    "\n",
    "- Simple\n",
    " - Training time on colab: ~ 1 hr\n",
    "- Medium\n",
    " - Training time on colab: 2 ~ 4 hr\n",
    "- Strong\n",
    " - Training time on colab: 5 ~ 6 hrs\n",
    "- Boss\n",
    " - **Unmeasurable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYO8InxavGsy"
   },
   "source": [
    "# Learning Curve (Strong Baseline)\n",
    "* This method is slightly different from colab.\n",
    "\n",
    "![Loss Curve](https://i.imgur.com/vIujQyo.png)\n",
    "\n",
    "# Accuracy Curve (Strong Baseline)\n",
    "* Note that you cannot access testing accuracy. But this plot tells you that even though the model overfits the training data, the testing accuracy is still improving, and that's why you need to train more epochs.\n",
    "\n",
    "![Acc Curve](https://i.imgur.com/4W1otXG.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6UfXzef-wNl"
   },
   "source": [
    "# Q&A\n",
    "\n",
    "If there are any problem related to Domain Adaptation, please email to b05902127@ntu.edu.tw / ntu-ml-2020spring-ta@googlegroups.com。\n",
    "\n",
    "The Q&A section might be updated to here if I have time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4TMXG_YCqVb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "hw11_domain_adaptation (en).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
